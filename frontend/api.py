#!/usr/bin/env python3
"""
Database Viewer API
æ•°æ®åº“æŸ¥çœ‹å™¨API

æä¾›pageså’Œchunksæ•°æ®çš„æŸ¥è¯¢æŽ¥å£ï¼Œæ”¯æŒåˆ†é¡µã€æŽ’åºã€æœç´¢å’Œç»Ÿè®¡åŠŸèƒ½ã€‚

=== æ ¸å¿ƒåŠŸèƒ½ ===

**PagesæŽ¥å£ (/api/pages)**
- åˆ†é¡µæŸ¥è¯¢ï¼šæ”¯æŒpageã€sizeå‚æ•°
- æŽ’åºåŠŸèƒ½ï¼šæ”¯æŒå¤šå­—æ®µæŽ’åºï¼ˆidã€urlã€crawl_countã€process_countã€created_atã€last_crawled_atï¼‰
- æœç´¢è¿‡æ»¤ï¼šæ”¯æŒURLå…³é”®è¯æœç´¢
- ç»Ÿè®¡ä¿¡æ¯ï¼šæä¾›çˆ¬å–é—´éš”æ—¶é—´ç»Ÿè®¡

**ChunksæŽ¥å£ (/api/chunks)**
- åˆ†é¡µæŸ¥è¯¢ï¼šæ”¯æŒpageã€sizeå‚æ•°
- å†…å®¹å±•ç¤ºï¼šæ˜¾ç¤ºchunkå†…å®¹å’Œç›¸å…³URLä¿¡æ¯

**ç»Ÿè®¡æŽ¥å£ (/api/stats)**
- é¡µé¢ç»Ÿè®¡ï¼šæ€»æ•°ã€æœ‰å†…å®¹é¡µé¢æ•°ã€å†…å®¹ç™¾åˆ†æ¯”
- å¤„ç†ç»Ÿè®¡ï¼šå¹³å‡çˆ¬å–æ¬¡æ•°ã€å¹³å‡å¤„ç†æ¬¡æ•°ï¼ˆä»…æœ‰å†…å®¹é¡µé¢ï¼‰
- ç²¾åº¦æŽ§åˆ¶ï¼šçˆ¬å–å’Œå¤„ç†æ¬¡æ•°ä¿ç•™4ä½å°æ•°ï¼Œç™¾åˆ†æ¯”ä¿ç•™2ä½å°æ•°

=== çˆ¬å–é—´éš”æ—¶é—´ç»Ÿè®¡ ===

**è®¡ç®—é€»è¾‘ï¼š**
- æ•°æ®è¿‡æ»¤ï¼šåªåŒ…å«crawl_count > 0çš„é¡µé¢ï¼ˆå·²å®žé™…çˆ¬å–çš„é¡µé¢ï¼‰
- æ—¶é—´æŽ’åºï¼šæŒ‰last_crawled_atå‡åºæŽ’åˆ—ç¡®ä¿æ—¶é—´é¡ºåº
- é—´éš”è®¡ç®—ï¼šè®¡ç®—ç›¸é‚»è®°å½•çš„æ—¶é—´å·®ï¼ˆç§’ï¼‰
- å¹³å‡å€¼ï¼šæ‰€æœ‰æ—¶é—´é—´éš”çš„ç®—æœ¯å¹³å‡å€¼

**ä¸šåŠ¡ä»·å€¼ï¼š**
- æŽ’é™¤æœªçˆ¬å–é¡µé¢ï¼šcrawl_count = 0çš„é¡µé¢åªæ˜¯è®°å½•ç­‰å¾…çˆ¬å–ï¼Œä¸å‚ä¸Žç»Ÿè®¡
- çœŸå®žæ€§èƒ½æŒ‡æ ‡ï¼šåæ˜ å®žé™…çˆ¬å–æ“ä½œçš„æ—¶é—´é—´éš”
- ç³»ç»Ÿç›‘æŽ§ï¼šå¸®åŠ©è¯„ä¼°çˆ¬å–é¢‘çŽ‡å’Œç³»ç»Ÿæ€§èƒ½
"""

import sys
from pathlib import Path
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from database.utils import get_database_client

app = FastAPI(title="Database Viewer API", version="1.0.0")

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/api/pages")
async def get_pages(search: str = "", sort: str = "last_crawled_at", order: str = "desc") -> JSONResponse:
    """èŽ·å–pagesè¡¨æ•°æ®ï¼ˆå›ºå®šå‰100æ¡ï¼‰"""
    try:
        client = await get_database_client()

        # æž„å»ºæŸ¥è¯¢æ¡ä»¶
        where_clause = "WHERE last_crawled_at IS NOT NULL"
        params = []
        if search:
            where_clause += " AND (url ILIKE $1 OR content ILIKE $1)"
            params.append(f"%{search}%")

        # æž„å»ºæŽ’åº - ä¼˜é›…çŽ°ä»£ç²¾ç®€
        valid_sorts = ["id", "url", "crawl_count", "process_count", "created_at", "last_crawled_at"]
        sort_column = sort if sort in valid_sorts else "last_crawled_at"
        sort_order = "ASC" if order.lower() == "asc" else "DESC"

        # èŽ·å–å‰100æ¡æ•°æ® - å›ºå®šæ•°é‡ï¼Œæ— åˆ†é¡µ
        query = f"""
            SELECT id, url, content, crawl_count, process_count, created_at, last_crawled_at
            FROM pages {where_clause}
            ORDER BY {sort_column} {sort_order}
            LIMIT 100
        """

        if search:
            pages = await client.fetch_all(query, params[0])
        else:
            pages = await client.fetch_all(query)

        # è®¡ç®—å¹³å‡çˆ¬å–é—´éš”æ—¶é—´ï¼ˆåªåŒ…å«å·²çˆ¬å–çš„é¡µé¢ï¼‰- ä¼˜é›…çŽ°ä»£ç²¾ç®€
        avg_crawl_interval = None
        crawled_pages = [page for page in pages if page["crawl_count"] > 0]

        if len(crawled_pages) >= 2:
            # æŒ‰last_crawled_atæŽ’åºï¼ˆç¡®ä¿æ—¶é—´é¡ºåºï¼‰
            sorted_pages = sorted(crawled_pages, key=lambda x: x["last_crawled_at"])
            intervals = []

            for i in range(1, len(sorted_pages)):
                prev_time = sorted_pages[i-1]["last_crawled_at"]
                curr_time = sorted_pages[i]["last_crawled_at"]

                # è®¡ç®—æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
                from datetime import datetime
                if isinstance(prev_time, str):
                    prev_dt = datetime.fromisoformat(prev_time.replace('Z', '+00:00'))
                    curr_dt = datetime.fromisoformat(curr_time.replace('Z', '+00:00'))
                else:
                    prev_dt = prev_time
                    curr_dt = curr_time

                interval_seconds = (curr_dt - prev_dt).total_seconds()
                intervals.append(interval_seconds)

            # è®¡ç®—å¹³å‡å€¼ï¼ˆintervalsåœ¨æ­¤ä½œç”¨åŸŸå†…å·²å®šä¹‰ï¼‰
            if intervals:
                avg_crawl_interval = sum(intervals) / len(intervals)

        # æ ¼å¼åŒ–æ•°æ®
        formatted_pages = []
        for page in pages:
            # ç®€åŒ–URLæ˜¾ç¤º
            display_url = page["url"]
            if display_url.startswith("https://developer.apple.com/documentation"):
                display_url = display_url.replace("https://developer.apple.com/documentation", "...")

            formatted_pages.append({
                "id": page["id"],  # æ•°æ®åº“å±‚å·²å¤„ç†UUIDåºåˆ—åŒ–
                "url": display_url,
                "full_url": page["url"],  # å®Œæ•´URL
                "content": page["content"][:100] + "..." if len(page["content"]) > 100 else page["content"],
                "full_content": page["content"],  # å®Œæ•´å†…å®¹
                "crawl_count": page["crawl_count"],
                "process_count": page["process_count"],
                "created_at": page["created_at"],  # æ•°æ®åº“å±‚å·²è½¬æ¢ä¸ºISOæ ¼å¼
                "last_crawled_at": page["last_crawled_at"]  # æ•°æ®åº“å±‚å·²è½¬æ¢ä¸ºISOæ ¼å¼
            })

        return JSONResponse({
            "success": True,
            "data": formatted_pages,
            "count": len(formatted_pages),
            "stats": {
                "avg_crawl_interval": f"{avg_crawl_interval:.2f}" if avg_crawl_interval else None,
                "data_count": len(crawled_pages) if 'crawled_pages' in locals() else 0
            }
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e),
            "data": []
        }, status_code=500)


@app.get("/api/chunks")
async def get_chunks(page: int = 1, size: int = 50, search: str = "",
                    page_id: str = "", sort: str = "created_at", order: str = "desc") -> JSONResponse:
    """èŽ·å–chunksè¡¨æ•°æ®ï¼ˆåˆ†é¡µï¼‰"""
    try:
        client = await get_database_client()

        # æž„å»ºæŸ¥è¯¢æ¡ä»¶
        where_conditions = []
        params = []

        if search:
            where_conditions.append("(url ILIKE $1 OR content ILIKE $1)")
            params.append(f"%{search}%")

        if page_id:
            param_index = len(params) + 1
            where_conditions.append(f"url IN (SELECT url FROM pages WHERE id = ${param_index}::uuid)")
            params.append(page_id)

        where_clause = "WHERE " + " AND ".join(where_conditions) if where_conditions else ""

        # æž„å»ºæŽ’åº
        valid_sorts = ["id", "url", "created_at"]
        sort_column = sort if sort in valid_sorts else "created_at"
        sort_order = "ASC" if order.lower() == "asc" else "DESC"

        # è®¡ç®—åˆ†é¡µ
        offset = (page - 1) * size

        # èŽ·å–æ€»æ•°
        count_query = f"SELECT COUNT(*) as total FROM chunks {where_clause}"
        total_result = await client.fetch_all(count_query, *params)
        total = total_result[0]["total"]

        # èŽ·å–åˆ†é¡µæ•°æ®
        limit_param = len(params) + 1
        offset_param = len(params) + 2
        query = f"""
            SELECT id, url, content, created_at, embedding
            FROM chunks {where_clause}
            ORDER BY {sort_column} {sort_order}
            LIMIT ${limit_param} OFFSET ${offset_param}
        """
        params.extend([size, offset])
        chunks = await client.fetch_all(query, *params)

        # æ ¼å¼åŒ–æ•°æ®
        formatted_chunks = []
        for chunk in chunks:
                # ç®€åŒ–URLæ˜¾ç¤º
                display_url = chunk["url"]
                if display_url.startswith("https://developer.apple.com/documentation"):
                    display_url = display_url.replace("https://developer.apple.com/documentation", "...")

                # å¤„ç†embeddingæ•°æ® - ç›´æŽ¥æ˜¾ç¤ºå‰5ä¸ªå€¼
                embedding_info = "æ— "
                if chunk["embedding"]:
                    try:
                        import ast
                        embedding_array = ast.literal_eval(chunk["embedding"])
                        if isinstance(embedding_array, list) and len(embedding_array) > 0:
                            # ç›´æŽ¥æ˜¾ç¤ºå‰5ä¸ªå€¼ï¼Œä¿ç•™4ä½å°æ•°
                            embedding_info = str([round(x, 4) for x in embedding_array[:5]])
                    except Exception:
                        embedding_info = "è§£æžé”™è¯¯"

                formatted_chunks.append({
                    "id": chunk["id"],  # æ•°æ®åº“å±‚å·²å¤„ç†UUIDåºåˆ—åŒ–
                    "url": display_url,
                    "full_url": chunk["url"],  # å®Œæ•´URL
                    "content": chunk["content"][:100] + "..." if len(chunk["content"]) > 100 else chunk["content"],
                    "full_content": chunk["content"],  # å®Œæ•´å†…å®¹
                    "created_at": chunk["created_at"],  # æ•°æ®åº“å±‚å·²è½¬æ¢ä¸ºISOæ ¼å¼
                    "embedding_info": embedding_info,
                    "raw_embedding": str(chunk["embedding"]) if chunk["embedding"] else None
                })

        return JSONResponse({
            "success": True,
            "data": formatted_chunks,
            "pagination": {
                "page": page,  # FastAPIå·²ç¡®ä¿æ˜¯æ•´æ•°
                "size": size,  # FastAPIå·²ç¡®ä¿æ˜¯æ•´æ•°
                "total": total,
                "pages": (total + size - 1) // size
            }
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e),
            "data": []
        }, status_code=500)


@app.get("/api/stats")
async def get_stats() -> JSONResponse:
    """èŽ·å–ç»Ÿè®¡ä¿¡æ¯"""
    try:
        client = await get_database_client()

        # åˆå¹¶æ‰€æœ‰ç»Ÿè®¡æŸ¥è¯¢ä¸ºå•ä¸ªå¤æ‚æŸ¥è¯¢ - å…¨å±€æœ€ä¼˜è§£
        stats = await client.fetch_all("""
            WITH page_stats AS (
                SELECT
                    COUNT(*) as total_pages,
                    COUNT(CASE WHEN content IS NOT NULL AND content != '' THEN 1 END) as pages_with_content,
                    AVG(crawl_count) as avg_crawl_count,
                    AVG(CASE WHEN content IS NOT NULL AND content != '' THEN process_count END) as avg_process_count,
                    COUNT(CASE WHEN crawl_count > 0 AND LENGTH(content) < 10 THEN 1 END) as anomalous_pages
                FROM pages
            ),
            chunk_stats AS (
                SELECT COUNT(*) as total_chunks FROM chunks
            )
            SELECT
                p.total_pages,
                c.total_chunks,
                p.pages_with_content,
                ROUND((p.pages_with_content::float / NULLIF(p.total_pages, 0) * 100)::numeric, 2) as content_percentage,
                ROUND(p.avg_crawl_count::numeric, 4) as avg_crawl_count,
                ROUND(p.avg_process_count::numeric, 4) as avg_process_count,
                p.anomalous_pages
            FROM page_stats p, chunk_stats c
        """)

        result = stats[0] if stats else {}

        # è½¬æ¢Decimalç±»åž‹ä¸ºfloatä»¥æ”¯æŒJSONåºåˆ—åŒ– - å…¨å±€æœ€ä¼˜è§£
        return JSONResponse({
            "success": True,
            "data": {
                "pages_count": result.get("total_pages", 0),
                "chunks_count": result.get("total_chunks", 0),
                "pages_with_content": result.get("pages_with_content", 0),
                "content_percentage": f"{float(result.get('content_percentage', 0)):.2f}",
                "avg_crawl_count": float(result.get("avg_crawl_count", 0)),
                "avg_process_count": float(result.get("avg_process_count", 0)),
                "anomalous_pages": result.get("anomalous_pages", 0)
            }
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e),
            "data": {
                "pages_count": 0,
                "chunks_count": 0,
                "pages_with_content": 0,
                "content_percentage": "0.00",
                "avg_crawl_count": 0,
                "avg_process_count": 0,
                "anomalous_pages": 0
            }
        }, status_code=500)


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {"message": "Database Viewer API", "version": "1.0.0"}


if __name__ == "__main__":
    print("ðŸš€ å¯åŠ¨æ•°æ®åº“æŸ¥çœ‹å™¨API...")
    print("ðŸ“Š APIåœ°å€: http://localhost:8001")
    print("ðŸ“– APIæ–‡æ¡£: http://localhost:8001/docs")
    
    uvicorn.run(
        "api:app",
        host="0.0.0.0",
        port=8001,
        reload=True,
        log_level="info"
    )
