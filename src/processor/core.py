"""
Pure Processor Core
Á∫ØÂ§ÑÁêÜÂô®Ê†∏ÂøÉÊ®°Âùó

‰∏ìÊ≥®‰∫éÂÜÖÂÆπÂ§ÑÁêÜÁöÑÁã¨Á´ãÁªÑ‰ª∂ÔºåÊòØÁªü‰∏ÄÁà¨Ëô´Á≥ªÁªüÁöÑÂ§ÑÁêÜÂºïÊìé„ÄÇ

=== Áªü‰∏ÄÁà¨Ëô´Á≥ªÁªüÊû∂ÊûÑ ===

Êú¨Ê®°ÂùóÊòØÁªü‰∏ÄÁà¨Ëô´Á≥ªÁªüÁöÑÊ†∏ÂøÉÁªÑ‰ª∂‰πã‰∏ÄÔºå‰∏éÁà¨ÂèñÂô®ÁªÑ‰ª∂ÂçèÂêåÂ∑•‰ΩúÔºö

**Á≥ªÁªüÊû∂ÊûÑÔºö**
- Áªü‰∏ÄÂÖ•Âè£Ôºötools/continuous_crawler.py Âπ∂ÂèëËøêË°åÁà¨ÂèñÂô®ÂíåÂ§ÑÁêÜÂô®
- ËÅåË¥£ÂàÜÁ¶ªÔºöÁà¨ÂèñÂô®‰∏ìÊ≥®Áà¨ÂèñÔºåÂ§ÑÁêÜÂô®‰∏ìÊ≥®ÂàÜÂùóÂµåÂÖ•
- Êï∞ÊçÆÂ∫ìÂçèË∞ÉÔºöÈÄöËøá crawl_count Âíå process_count ÂÆûÁé∞Êô∫ËÉΩË∞ÉÂ∫¶

**Â§ÑÁêÜÂô®ËÅåË¥£Ôºö**
- ‰ªé pages Ë°®ËØªÂèñÂ∑≤Áà¨ÂèñÁöÑÈ°µÈù¢ÂÜÖÂÆπ
- Êô∫ËÉΩÂàÜÂùóÂ§ÑÁêÜÔºàH1/H2/H3ÂàÜÂ±ÇÁ≠ñÁï•Ôºâ
- ÂêëÈáèÂµåÂÖ•ÁîüÊàêÔºàQwen3-Embedding-4BÔºâ
- chunks Êï∞ÊçÆÂ≠òÂÇ®Âíå process_count ÁÆ°ÁêÜ

=== Â§ÑÁêÜÊµÅÁ®ãËÆæËÆ° ===

**‰ºòÂÖàÁ∫ßË∞ÉÂ∫¶Ôºö**
- Âü∫‰∫é process_count ÊúÄÂ∞èÂÄº‰ºòÂÖàÂ§ÑÁêÜ
- Á°Æ‰øùÊâÄÊúâÈ°µÈù¢ÂæóÂà∞ÂùáË°°Â§ÑÁêÜ
- Ëá™Âä®Âπ≥Ë°°Á≥ªÁªüË¥üËΩΩ

**Â§ÑÁêÜÊµÅÁ®ãÔºö**
1. Ëé∑ÂèñÊúÄÂ∞è process_count ÁöÑÈ°µÈù¢ÂÜÖÂÆπ
2. Âà†Èô§ËØ•URLÁöÑÊâÄÊúâÊóßchunksÔºàÁ°Æ‰øùÊï∞ÊçÆ‰∏ÄËá¥ÊÄßÔºâ
3. Êô∫ËÉΩÂàÜÂùóÔºö‰ΩøÁî®SmartChunkerÁöÑÂàÜÂ±ÇÁ≠ñÁï•
4. ÂêëÈáèÂµåÂÖ•Ôºö‰∏∫ÊØè‰∏™chunkÁîüÊàê2560Áª¥ÂµåÂÖ•ÂêëÈáè
5. Êï∞ÊçÆÂ≠òÂÇ®ÔºöÊèíÂÖ•Êñ∞chunksÂπ∂Êõ¥Êñ∞process_count

**ÂÆπÈîôÊú∫Âà∂Ôºö**
- Á©∫ÂÜÖÂÆπÈ°µÈù¢Ë∑≥ËøáÂ§ÑÁêÜ‰ΩÜÊõ¥Êñ∞ËÆ°Êï∞
- ÂàÜÂùóÂ§±Ë¥•Êó∂ËÆ∞ÂΩïÈîôËØØ‰ΩÜÁªßÁª≠Â§ÑÁêÜ
- ÂµåÂÖ•Â§±Ë¥•Êó∂Ë∑≥ËøáËØ•chunk‰ΩÜ‰∏ç‰∏≠Êñ≠ÊµÅÁ®ã
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from database import get_database_client, DatabaseOperations
from chunking import SmartChunker
from embedding import create_embedding
from utils.logger import setup_logger
import asyncio

logger = setup_logger(__name__)


class PureProcessor:
    """Pure processor component - only content processing and chunks storage"""

    def __init__(self):
        self.db_client = None
        self.db_operations = None
        self.chunker = SmartChunker()

    async def __aenter__(self):
        await self.initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.cleanup()

    async def initialize(self) -> None:
        """Initialize database connections"""
        logger.info("Initializing pure processor")
        self.db_client = await get_database_client()
        self.db_operations = DatabaseOperations(self.db_client)

    async def cleanup(self) -> None:
        """Clean up resources"""
        logger.info("Cleaning up processor resources")

    async def start_infinite_process(self) -> None:
        """Start infinite processing loop based on process_count priority"""
        logger.info("Starting pure processor")

        process_count = 0
        while True:
            try:
                # Get next URL to process (minimum process_count)
                result = await self.db_operations.get_next_process_url()
                if not result:
                    logger.info("No URLs to process")
                    await asyncio.sleep(5)  # Wait before checking again
                    continue

                next_url, content = result
                process_count += 1
                logger.info(f"=== Process #{process_count}: {next_url} ===")

                # Process the page content
                await self._process_page_content(next_url, content)

            except KeyboardInterrupt:
                logger.info("Processor interrupted by user")
                break
            except Exception as e:
                logger.error(f"Process error: {e}")
                continue

    async def _process_page_content(self, url: str, content: str) -> None:
        """Process single page content: chunking + embedding + storage"""
        logger.info(f"Processing content for: {url}")

        # Skip if no content
        if not content.strip():
            logger.error(f"‚ùå No content to process for {url}")
            await self.db_operations.update_page_after_process(url)
            return

        # Delete old chunks for this URL
        await self.db_operations.delete_chunks_by_url(url)

        # Process content: chunking + embedding + storage
        chunks = self.chunker.chunk_text(content)
        if not chunks:
            logger.error(f"‚ùå No chunks generated for {url}")
            await self.db_operations.update_page_after_process(url)
            return

        # Validate chunk lengths
        for i, chunk in enumerate(chunks):
            if len(chunk) < 128:
                logger.error(f"‚ö†Ô∏è Chunk {i+1} ÈïøÂ∫¶ËøáÁü≠: {len(chunk)} Â≠óÁ¨¶ (ÊúÄÂ∞èË¶ÅÊ±Ç: 128) - URL: {url}")

        data_to_insert = []
        for i, chunk in enumerate(chunks):
            logger.info(f"Processing chunk {i+1}/{len(chunks)}, length: {len(chunk)}")
            if not chunk.strip():
                logger.error(f"‚ùå Empty chunk {i+1} for {url}, skipping")
                continue
            
            embedding = create_embedding(chunk)
            data_to_insert.append({
                "url": url,
                "content": chunk,
                "embedding": str(embedding)
            })

        if not data_to_insert:
            logger.error(f"‚ùå No data to insert for {url}")
            await self.db_operations.update_page_after_process(url)
            return

        # Insert chunks and update process count
        await self.db_operations.insert_chunks(data_to_insert)
        await self.db_operations.update_page_after_process(url)

        logger.info(f"‚úÖ Processed {url}: {len(chunks)} chunks created")


async def main():
    """Main function for direct execution"""
    logger.info("üöÄ Pure Processor Starting")

    try:
        async with PureProcessor() as processor:
            await processor.start_infinite_process()
    except KeyboardInterrupt:
        logger.info("Processor interrupted by user")
    except Exception as e:
        logger.error(f"Processor error: {e}")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Processor interrupted by user")
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        import sys
        sys.exit(1)
