"""
Pure Processor Core
çº¯å¤„ç†å™¨æ ¸å¿ƒæ¨¡å—

ä¸“æ³¨äºå†…å®¹å¤„ç†çš„ç‹¬ç«‹ç»„ä»¶ï¼Œæ˜¯ç»Ÿä¸€çˆ¬è™«ç³»ç»Ÿçš„å¤„ç†å¼•æ“ã€‚

=== ç»Ÿä¸€çˆ¬è™«ç³»ç»Ÿæ¶æ„ ===

æœ¬æ¨¡å—æ˜¯ç»Ÿä¸€çˆ¬è™«ç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ä¹‹ä¸€ï¼Œä¸çˆ¬å–å™¨ç»„ä»¶ååŒå·¥ä½œï¼š

**ç³»ç»Ÿæ¶æ„ï¼š**
- ç»Ÿä¸€å…¥å£ï¼štools/continuous_crawler.py å¹¶å‘è¿è¡Œçˆ¬å–å™¨å’Œå¤„ç†å™¨
- èŒè´£åˆ†ç¦»ï¼šçˆ¬å–å™¨ä¸“æ³¨çˆ¬å–ï¼Œå¤„ç†å™¨ä¸“æ³¨åˆ†å—åµŒå…¥
- æ•°æ®åº“åè°ƒï¼šé€šè¿‡ crawl_count å’Œ process_count å®ç°æ™ºèƒ½è°ƒåº¦

**å¤„ç†å™¨èŒè´£ï¼š**
- ä» pages è¡¨è¯»å–å·²çˆ¬å–çš„é¡µé¢å†…å®¹
- æ™ºèƒ½åˆ†å—å¤„ç†ï¼ˆH1/H2/H3åˆ†å±‚ç­–ç•¥ï¼‰
- å‘é‡åµŒå…¥ç”Ÿæˆï¼ˆQwen3-Embedding-4Bï¼‰
- chunks æ•°æ®å­˜å‚¨å’Œ process_count ç®¡ç†

=== å¤„ç†æµç¨‹è®¾è®¡ ===

**ä¼˜å…ˆçº§è°ƒåº¦ï¼š**
- åŸºäº process_count æœ€å°å€¼ä¼˜å…ˆå¤„ç†
- ç¡®ä¿æ‰€æœ‰é¡µé¢å¾—åˆ°å‡è¡¡å¤„ç†
- è‡ªåŠ¨å¹³è¡¡ç³»ç»Ÿè´Ÿè½½

**å¤„ç†æµç¨‹ï¼š**
1. è·å–æœ€å° process_count çš„é¡µé¢å†…å®¹
2. åˆ é™¤è¯¥URLçš„æ‰€æœ‰æ—§chunksï¼ˆç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼‰
3. æ™ºèƒ½åˆ†å—ï¼šä½¿ç”¨SmartChunkerçš„åˆ†å±‚ç­–ç•¥
4. å‘é‡åµŒå…¥ï¼šä¸ºæ¯ä¸ªchunkç”Ÿæˆ2560ç»´åµŒå…¥å‘é‡
5. æ•°æ®å­˜å‚¨ï¼šæ’å…¥æ–°chunkså¹¶æ›´æ–°process_count

**å®¹é”™æœºåˆ¶ï¼š**
- ç©ºå†…å®¹é¡µé¢è·³è¿‡å¤„ç†ä½†æ›´æ–°è®¡æ•°
- åˆ†å—å¤±è´¥æ—¶è®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†
- åµŒå…¥å¤±è´¥æ—¶è·³è¿‡è¯¥chunkä½†ä¸ä¸­æ–­æµç¨‹
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from database import get_database_client, DatabaseOperations
from chunking import SmartChunker
from embedding import create_embedding
from utils.logger import setup_logger
import asyncio

logger = setup_logger(__name__)


class ContentProcessor:
    """å†…å®¹å¤„ç†å™¨ï¼Œä¸“æ³¨äºåˆ†å—å’ŒåµŒå…¥å¤„ç†"""

    def __init__(self):
        self.db_client = None
        self.db_operations = None
        self.chunker = SmartChunker()

    async def __aenter__(self):
        await self.initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.cleanup()

    async def initialize(self) -> None:
        """Initialize database connections"""
        logger.info("Initializing pure processor")
        self.db_client = await get_database_client()
        self.db_operations = DatabaseOperations(self.db_client)

    async def cleanup(self) -> None:
        """Clean up resources"""
        logger.info("Cleaning up processor resources")

    async def start_processing(self) -> None:
        """å¼€å§‹å†…å®¹å¤„ç†å¾ªç¯"""
        logger.info("Starting pure processor")

        process_count = 0
        while True:
            try:
                # Get next URL to process (minimum process_count)
                result = await self.db_operations.get_process_url()
                # if not result:
                #     logger.info("No URLs to process")
                #     await asyncio.sleep(3)  # Wait before checking again
                #     continue

                next_url, content = result
                process_count += 1
                logger.info(f"=== Process #{process_count}: {next_url} ===")

                # Process the page content
                await self._process_content(next_url, content)

            except KeyboardInterrupt:
                logger.info("Processor interrupted by user")
                break
            except Exception as e:
                logger.error(f"Process error: {e}")
                continue

    async def _process_content(self, url: str, content: str) -> None:
        """å¤„ç†é¡µé¢å†…å®¹ï¼šåˆ†å— + åµŒå…¥ + å­˜å‚¨"""
        logger.info(f"Processing content for: {url}")

        # Skip if no content
        if not content.strip():
            logger.error(f"âŒ No content to process for {url}")
            await self.db_operations.update_process_count(url)
            return

        # Delete old chunks for this URL
        await self.db_operations.delete_chunks_by_url(url)

        # Process content: chunking + embedding + storage
        chunks = self.chunker.chunk_text(content)
        if not chunks:
            logger.error(f"âŒ No chunks generated for {url}")
            await self.db_operations.update_process_count(url)
            return

        # Validate chunk lengths
        for i, chunk in enumerate(chunks):
            if len(chunk) < 128:
                logger.error(f"âš ï¸ Chunk {i+1} é•¿åº¦è¿‡çŸ­: {len(chunk)} å­—ç¬¦ (æœ€å°è¦æ±‚: 128) - URL: {url}")

        data_to_insert = []
        for i, chunk in enumerate(chunks):
            logger.info(f"Processing chunk {i+1}/{len(chunks)}, length: {len(chunk)}")
            if not chunk.strip():
                logger.error(f"âŒ Empty chunk {i+1} for {url}, skipping")
                continue
            
            embedding = create_embedding(chunk)
            data_to_insert.append({
                "url": url,
                "content": chunk,
                "embedding": str(embedding)
            })

        if not data_to_insert:
            logger.error(f"âŒ No data to insert for {url}")
            await self.db_operations.update_process_count(url)
            return

        # Insert chunks and update process count
        await self.db_operations.insert_chunks(data_to_insert)
        await self.db_operations.update_process_count(url)

        logger.info(f"âœ… Processed {url}: {len(chunks)} chunks created")


async def main():
    """Main function for direct execution"""
    logger.info("ğŸš€ Pure Processor Starting")

    try:
        async with ContentProcessor() as processor:
            await processor.start_processing()
    except KeyboardInterrupt:
        logger.info("Processor interrupted by user")
    except Exception as e:
        logger.error(f"Processor error: {e}")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Processor interrupted by user")
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        import sys
        sys.exit(1)
