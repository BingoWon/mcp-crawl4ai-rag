#!/usr/bin/env python3
"""
Appleç½‘ç«™éšè”½çˆ¬è™«
åŸºäºçœŸå®æµè§ˆå™¨è¯·æ±‚å¤´çš„ç²¾ç¡®ä¼ªè£…å®ç°
"""

from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
from typing import Dict, Any, Optional
import asyncio


class AppleStealthCrawler:
    """Appleç½‘ç«™ä¸“ç”¨éšè”½çˆ¬è™«"""

    def __init__(self):
        """åˆå§‹åŒ–Appleéšè”½çˆ¬è™«"""
        self.browser_config = self._create_stealth_browser_config()
        self.crawler_config = self._create_stealth_crawler_config()
        self.crawler: Optional[AsyncWebCrawler] = None

    def _create_stealth_browser_config(self) -> BrowserConfig:
        """åˆ›å»ºå®Œç¾ä¼ªè£…çš„æµè§ˆå™¨é…ç½®"""
        return BrowserConfig(
            headless=True,  # é™é»˜è¿è¡Œï¼Œä¸å¼¹å‡ºæµè§ˆå™¨çª—å£
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36 Edg/138.0.0.0",
            viewport_width=1920,
            viewport_height=1080,
            headers=self._get_apple_headers(),
            extra_args=[
                "--disable-blink-features=AutomationControlled",
                "--exclude-switches=enable-automation",
                "--disable-dev-shm-usage",
                "--no-sandbox",
                "--disable-gpu",
                "--disable-extensions",
                "--disable-plugins",
                "--disable-background-timer-throttling",
                "--disable-renderer-backgrounding",
                "--disable-backgrounding-occluded-windows",
                "--no-first-run",
                "--disable-default-apps",
                "--disable-features=TranslateUI",
                "--disable-ipc-flooding-protection"
            ]
        )

    def _create_stealth_crawler_config(self) -> CrawlerRunConfig:
        """åˆ›å»ºéšè”½çˆ¬è™«è¿è¡Œé…ç½®"""
        return CrawlerRunConfig(
            cache_mode=CacheMode.BYPASS,
            word_count_threshold=10,
            delay_before_return_html=3.0,
            page_timeout=15000,
            remove_overlay_elements=True,
            # ç²¾ç¡®å®šä½Appleæ–‡æ¡£ä¸»è¦å†…å®¹åŒºåŸŸ
            css_selector="#app-main",
            # è¿‡æ»¤æ‰å¯¼èˆªå’Œé¡µè„šæ ‡ç­¾ï¼Œ2025 å¹´ 7 æœˆ 13 æ—¥ï¼Œè¿™éƒ¨åˆ†æ²¡æœ‰å¯ç”¨ï¼Œæ˜¯å› ä¸ºå¯ç”¨äº†ä¼šè¿‡æ»¤åˆ°æ–‡æ¡£ä¸­çš„ Deprecated asideå†…å®¹
            # excluded_tags=['nav', 'header', 'footer', 'aside'],
            # ç§»é™¤å¤–éƒ¨é“¾æ¥å’Œç¤¾äº¤åª’ä½“é“¾æ¥
            exclude_external_links=False,  # ä¿ç•™Appleå†…éƒ¨çš„å¤–éƒ¨é“¾æ¥
            exclude_social_media_links=True
        )
    
    def _get_apple_headers(self) -> Dict[str, str]:
        """è·å–Appleç½‘ç«™ä¸“ç”¨è¯·æ±‚å¤´"""
        return {
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept-Language": "en-US,en;q=0.9",
            "Cache-Control": "no-cache",
            "Pragma": "no-cache",
            "Sec-CH-UA": '"Not)A;Brand";v="8", "Chromium";v="138", "Microsoft Edge";v="138"',
            "Sec-CH-UA-Mobile": "?0",
            "Sec-CH-UA-Platform": '"macOS"',
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
            "Upgrade-Insecure-Requests": "1",
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36 Edg/138.0.0.0"
        }
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.crawler = AsyncWebCrawler(config=self.browser_config)
        await self.crawler.__aenter__()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.crawler:
            await self.crawler.__aexit__(exc_type, exc_val, exc_tb)
    
    async def crawl(self, url: str) -> Dict[str, Any]:
        """çˆ¬å–æŒ‡å®šURL"""
        if not self.crawler:
            raise RuntimeError("Crawler not initialized. Use async with statement.")
        
        result = await self.crawler.arun(url=url, config=self.crawler_config)
        
        return {
            "success": result.success,
            "url": url,
            "markdown": result.markdown if result.success else None,
            "error": result.error_message if not result.success else None,
            "content_length": len(result.markdown) if result.success and result.markdown else 0
        }


async def test_apple_stealth_crawling():
    """æµ‹è¯•Appleéšè”½çˆ¬è™«"""
    test_url = "https://developer.apple.com/documentation/realitykit"
    
    print("ğŸ•µï¸ å¼€å§‹Appleéšè”½çˆ¬å–æµ‹è¯•")
    print(f"ğŸ¯ ç›®æ ‡URL: {test_url}")
    print("=" * 60)
    
    async with AppleStealthCrawler() as crawler:
        result = await crawler.crawl(test_url)
        
        print(f"âœ… çˆ¬å–çŠ¶æ€: {'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
        print(f"ğŸ“Š å†…å®¹é•¿åº¦: {result['content_length']} å­—ç¬¦")
        
        if result['success'] and result['markdown']:
            print(f"ğŸ“ å†…å®¹é¢„è§ˆ (å‰500å­—ç¬¦):")
            print("-" * 40)
            print(result['markdown'][:500])
            print("-" * 40)
        elif not result['success']:
            print(f"âŒ é”™è¯¯ä¿¡æ¯: {result['error']}")
        
        return result


if __name__ == "__main__":
    asyncio.run(test_apple_stealth_crawling())
