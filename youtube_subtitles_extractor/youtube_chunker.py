#!/usr/bin/env python3
"""
YouTubeå­—å¹•ä¸“ç”¨åˆ†å—å™¨

æç®€åŒ–ç®—æ³•ï¼š
1. ä»ä½ç½®0å¼€å§‹ï¼Œå‘åå–2500å­—ç¬¦
2. ä»ç¬¬2500å­—ç¬¦ä½ç½®å¼€å§‹ï¼Œæ‰¾ç¬¬ä¸€ä¸ªè‹±æ–‡å¥å·ï¼ˆ.ï¼‰
3. ä»èµ·å§‹ä½ç½®åˆ°å¥å·ä½ç½®+1 = ä¸€ä¸ªchunk
4. JSONåŒ…è£…ï¼š{"context": "è§†é¢‘æ ‡é¢˜", "content": "chunkå†…å®¹"}
5. ä¸‹ä¸€ä¸ªchunkä»å¥å·åå¼€å§‹ï¼Œé‡å¤æµç¨‹
"""

import json
import sys
from pathlib import Path
from typing import List, Dict, Any


class YouTubeChunker:
    """YouTubeå­—å¹•ä¸“ç”¨åˆ†å—å™¨"""

    def __init__(self):
        pass
    
    def chunk_youtube_subtitle(self, video_data: Dict[str, str]) -> List[Dict[str, str]]:
        """
        å¯¹YouTubeå­—å¹•è¿›è¡Œåˆ†å— - åŠ¨æ€chunkå¤§å°ç­–ç•¥

        Args:
            video_data: {"context": "è§†é¢‘æ ‡é¢˜", "content": "å®Œæ•´å­—å¹•"}

        Returns:
            List of chunks: [{"context": "æ ‡é¢˜", "content": "åˆ†å—å†…å®¹"}, ...]
        """
        context = video_data["context"]
        content = video_data["content"]

        if not content.strip():
            return []

        # åŠ¨æ€è®¡ç®—chunkå¤§å°
        total_length = len(content)
        chunk_count = max(1, total_length // 2500)  # è‡³å°‘1ä¸ªchunk
        chunk_size = total_length // chunk_count

        print(f"ğŸ“Š åŠ¨æ€åˆ†å—è®¡ç®—: æ€»é•¿åº¦={total_length}, chunkæ•°é‡={chunk_count}, chunkå¤§å°={chunk_size}")

        chunks = []
        position = 0
        current_chunk_index = 0

        while position < len(content) and current_chunk_index < chunk_count:
            # è®¡ç®—è¿™ä¸ªchunkçš„ç»“æŸä½ç½®
            chunk_end = self._find_chunk_end(content, position, chunk_size, current_chunk_index, chunk_count)

            # æå–chunkå†…å®¹
            chunk_content = content[position:chunk_end].strip()

            if chunk_content:  # åªæœ‰éç©ºå†…å®¹æ‰æ·»åŠ 
                chunk = {
                    "context": context,
                    "content": chunk_content
                }
                chunks.append(chunk)

            # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªä½ç½®
            position = chunk_end
            current_chunk_index += 1

        return chunks
    
    def _find_chunk_end(self, content: str, start_pos: int, chunk_size: int,
                        current_chunk_index: int, total_chunk_count: int) -> int:
        """
        æ‰¾åˆ°chunkçš„ç»“æŸä½ç½® - æœ€åchunkç‰¹æ®Šå¤„ç† + æœ€è¿‘å¥å·ç­–ç•¥

        Args:
            content: å®Œæ•´å†…å®¹
            start_pos: å¼€å§‹ä½ç½®
            chunk_size: åŠ¨æ€è®¡ç®—çš„chunkå¤§å°
            current_chunk_index: å½“å‰chunkç´¢å¼•
            total_chunk_count: æ€»chunkæ•°é‡

        Returns:
            chunkç»“æŸä½ç½®
        """
        # å¦‚æœæ˜¯æœ€åä¸€ä¸ªchunkï¼Œç›´æ¥è¿”å›å†…å®¹ç»“å°¾
        if current_chunk_index == total_chunk_count - 1:
            return len(content)

        # å¦‚æœå‰©ä½™å†…å®¹ä¸è¶³chunk_sizeå­—ç¬¦ï¼Œç›´æ¥è¿”å›ç»“å°¾
        if start_pos + chunk_size >= len(content):
            return len(content)

        target_pos = start_pos + chunk_size

        # å‘å‰æ‰¾æœ€è¿‘çš„å¥å·
        backward_pos = None
        for i in range(target_pos, start_pos - 1, -1):  # ä¸èƒ½è¶…è¿‡start_pos
            if content[i] == '.':
                backward_pos = i + 1  # åŒ…å«å¥å·
                break

        # å‘åæ‰¾æœ€è¿‘çš„å¥å·
        forward_pos = None
        for i in range(target_pos, len(content)):
            if content[i] == '.':
                forward_pos = i + 1  # åŒ…å«å¥å·
                break

        # é€‰æ‹©è·ç¦»æœ€è¿‘çš„å¥å·
        if backward_pos is None and forward_pos is None:
            # æ²¡æ‰¾åˆ°å¥å·ï¼Œè¿”å›å†…å®¹ç»“å°¾
            return len(content)
        elif backward_pos is None:
            # åªæœ‰å‘åçš„å¥å·
            return forward_pos
        elif forward_pos is None:
            # åªæœ‰å‘å‰çš„å¥å·
            return backward_pos
        else:
            # ä¸¤ä¸ªéƒ½æœ‰ï¼Œé€‰æ‹©è·ç¦»æœ€è¿‘çš„
            backward_distance = target_pos - (backward_pos - 1)  # backward_poså·²ç»+1äº†
            forward_distance = (forward_pos - 1) - target_pos    # forward_poså·²ç»+1äº†

            if backward_distance <= forward_distance:
                return backward_pos
            else:
                return forward_pos
    
    def chunk_to_json_strings(self, chunks: List[Dict[str, str]]) -> List[str]:
        """
        å°†chunksè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆä¸ç°æœ‰chunksè¡¨æ ¼å¼ä¸€è‡´ï¼‰
        
        Args:
            chunks: chunkå­—å…¸åˆ—è¡¨
            
        Returns:
            JSONå­—ç¬¦ä¸²åˆ—è¡¨
        """
        json_strings = []
        for chunk in chunks:
            json_str = json.dumps(chunk, ensure_ascii=False, indent=2)
            json_strings.append(json_str)
        
        return json_strings
    
    def analyze_chunks(self, chunks: List[Dict[str, str]]) -> Dict[str, Any]:
        """
        åˆ†æchunksçš„ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            chunks: chunkåˆ—è¡¨
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not chunks:
            return {"total_chunks": 0}
        
        lengths = [len(chunk["content"]) for chunk in chunks]
        
        stats = {
            "total_chunks": len(chunks),
            "min_length": min(lengths),
            "max_length": max(lengths),
            "avg_length": sum(lengths) / len(lengths),
            "total_length": sum(lengths),
            "context": chunks[0]["context"]  # æ‰€æœ‰chunksçš„contextåº”è¯¥ç›¸åŒ
        }
        
        return stats


def test_youtube_chunker():
    """æµ‹è¯•YouTubeåˆ†å—å™¨ - æ‰©å¤§æµ‹è¯•èŒƒå›´"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•YouTubeå­—å¹•åˆ†å—å™¨...")
    print("=" * 60)

    chunker = YouTubeChunker()

    # æ‰«ææ‰€æœ‰JSONæ–‡ä»¶è¿›è¡Œæµ‹è¯•
    subtitles_dir = Path("subtitles")
    all_files = list(subtitles_dir.glob("*.json"))

    # é€‰æ‹©ä¸åŒé•¿åº¦çš„æµ‹è¯•æ–‡ä»¶ï¼ˆæœ€å¤šæµ‹è¯•15ä¸ªï¼‰
    test_files = sorted(all_files)[:15]

    print(f"ğŸ“ æ‰¾åˆ° {len(all_files)} ä¸ªJSONæ–‡ä»¶ï¼Œæµ‹è¯•å‰ {len(test_files)} ä¸ª")
    print("=" * 60)

    # å…¨å±€ç»Ÿè®¡æ•°æ®
    all_chunks_data = []
    total_videos = 0
    total_chunks = 0

    for test_file in test_files:
        file_path = test_file  # test_fileså·²ç»æ˜¯Pathå¯¹è±¡

        if not file_path.exists():
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {test_file.name}")
            continue
        
        print(f"\nğŸ“ æµ‹è¯•æ–‡ä»¶: {test_file.name}")
        print("-" * 40)
        
        try:
            # è¯»å–åŸå§‹æ•°æ®
            with open(file_path, 'r', encoding='utf-8') as f:
                video_data = json.load(f)
            
            original_length = len(video_data["content"])
            print(f"ğŸ“Š åŸå§‹é•¿åº¦: {original_length:,} å­—ç¬¦")
            print(f"ğŸ“‹ è§†é¢‘æ ‡é¢˜: {video_data['context']}")
            
            # è¿›è¡Œåˆ†å—
            chunks = chunker.chunk_youtube_subtitle(video_data)
            
            # åˆ†æç»“æœ
            stats = chunker.analyze_chunks(chunks)
            
            print(f"ğŸ“ˆ åˆ†å—ç»“æœ:")
            print(f"   æ€»å—æ•°: {stats['total_chunks']}")
            print(f"   æœ€å°é•¿åº¦: {stats['min_length']:,} å­—ç¬¦")
            print(f"   æœ€å¤§é•¿åº¦: {stats['max_length']:,} å­—ç¬¦")
            print(f"   å¹³å‡é•¿åº¦: {stats['avg_length']:.0f} å­—ç¬¦")
            print(f"   æ€»é•¿åº¦: {stats['total_length']:,} å­—ç¬¦")
            
            # éªŒè¯å†…å®¹å®Œæ•´æ€§
            total_chunked = sum(len(chunk["content"]) for chunk in chunks)
            loss_ratio = (original_length - total_chunked) / original_length * 100
            print(f"   å†…å®¹æŸå¤±: {loss_ratio:.2f}%")

            # æ”¶é›†å®Œæ•´JSON chunké•¿åº¦æ•°æ®
            json_chunks = chunker.chunk_to_json_strings(chunks)
            json_lengths = [len(json_str) for json_str in json_chunks]
            all_chunks_data.extend(json_lengths)
            total_videos += 1
            total_chunks += len(chunks)

            # æ˜¾ç¤ºå®Œæ•´JSON chunké•¿åº¦åˆ†å¸ƒ
            print(f"   JSONé•¿åº¦åˆ†å¸ƒ: {min(json_lengths)}-{max(json_lengths)} å­—ç¬¦")

            # æ˜¾ç¤ºè¯¦ç»†åˆ†è§£ï¼ˆä»…å‰3ä¸ªè§†é¢‘ï¼‰
            if total_videos <= 3:
                print(f"   è¯¦ç»†åˆ†è§£:")
                for i, (chunk, json_str) in enumerate(zip(chunks[:2], json_chunks[:2])):
                    content_len = len(chunk["content"])
                    context_len = len(chunk["context"])
                    json_len = len(json_str)
                    overhead = json_len - content_len - context_len
                    print(f"     Chunk {i+1}: content={content_len}, context={context_len}, JSONæ€»é•¿={json_len}, å¼€é”€={overhead}")

            # ä¿å­˜æµ‹è¯•ç»“æœï¼ˆåªä¿å­˜å‰3ä¸ªæ–‡ä»¶çš„è¯¦ç»†ç»“æœï¼‰
            if total_videos <= 3:
                output_file = Path(f"test_chunks_{test_file.name}")

                with open(output_file, 'w', encoding='utf-8') as f:
                    for i, json_chunk in enumerate(json_chunks):
                        f.write(f"=== Chunk {i+1} ===\n")
                        f.write(json_chunk)
                        f.write("\n\n")

                print(f"ğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜: {output_file}")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

    # å…¨å±€ç»Ÿè®¡åˆ†æ
    print("\n" + "=" * 60)
    print("ğŸ“Š å…¨å±€æµ‹è¯•ç»Ÿè®¡")
    print("=" * 60)

    if all_chunks_data:
        print(f"ğŸ“ˆ æ€»ä½“æ•°æ®:")
        print(f"   æµ‹è¯•è§†é¢‘æ•°: {total_videos}")
        print(f"   æ€»chunkæ•°: {total_chunks}")
        print(f"   å¹³å‡æ¯è§†é¢‘: {total_chunks/total_videos:.1f} chunks")

        print(f"\nğŸ“ å®Œæ•´JSON Chunkå¤§å°ç»Ÿè®¡:")
        print(f"   å…¨å±€æœ€å°: {min(all_chunks_data):,} å­—ç¬¦")
        print(f"   å…¨å±€æœ€å¤§: {max(all_chunks_data):,} å­—ç¬¦")
        print(f"   å…¨å±€å¹³å‡: {sum(all_chunks_data)/len(all_chunks_data):.0f} å­—ç¬¦")
        print(f"   å…¨å±€ä¸­ä½æ•°: {sorted(all_chunks_data)[len(all_chunks_data)//2]:,} å­—ç¬¦")

        # é•¿åº¦åˆ†å¸ƒç»Ÿè®¡
        ranges = [
            (0, 1000), (1000, 2000), (2000, 2500),
            (2500, 3000), (3000, 4000), (4000, 10000)
        ]
        print(f"\nğŸ“Š é•¿åº¦åˆ†å¸ƒ:")
        for min_len, max_len in ranges:
            count = sum(1 for l in all_chunks_data if min_len <= l < max_len)
            if count > 0:
                percentage = count / len(all_chunks_data) * 100
                print(f"   {min_len:,}-{max_len:,}: {count:3d} ä¸ª ({percentage:.1f}%)")

    print("\n" + "=" * 60)
    print("âœ… æ‰©å¤§æµ‹è¯•å®Œæˆï¼")


def main():
    """ä¸»å‡½æ•°"""
    test_youtube_chunker()


if __name__ == "__main__":
    main()
