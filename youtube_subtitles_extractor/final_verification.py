#!/usr/bin/env python3
"""
YouTubeå­—å¹•å¤„ç†æœ€ç»ˆéªŒè¯è„šæœ¬

åŠŸèƒ½ï¼š
1. æ£€æŸ¥æ‰€æœ‰YouTubeè§†é¢‘çš„å¤„ç†çŠ¶æ€
2. ç»Ÿè®¡æ€»ä½“å¤„ç†ç»“æœ
3. éªŒè¯æ˜¯å¦æœ‰é—æ¼çš„è§†é¢‘
4. ç”Ÿæˆæœ€ç»ˆå®ŒæˆæŠ¥å‘Š
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv(project_root / ".env")

from src.database import create_database_client
from src.utils.logger import setup_logger

logger = setup_logger(__name__)


class FinalVerification:
    """æœ€ç»ˆéªŒè¯å™¨"""
    
    def __init__(self):
        self.db_client = None
        
    async def initialize(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        logger.info("ğŸ”— åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
        self.db_client = create_database_client()
        await self.db_client.initialize()
        logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    
    async def verify_completion(self):
        """éªŒè¯å¤„ç†å®ŒæˆçŠ¶æ€"""
        logger.info("ğŸ” å¼€å§‹æœ€ç»ˆéªŒè¯...")
        
        # 1. æ£€æŸ¥æ€»ä½“ç»Ÿè®¡
        total_stats = await self._get_total_stats()
        
        # 2. æ£€æŸ¥æœªå¤„ç†è§†é¢‘
        unprocessed_videos = await self._get_unprocessed_videos()
        
        # 3. æ£€æŸ¥chunksç»Ÿè®¡
        chunks_stats = await self._get_chunks_stats()
        
        # 4. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self._generate_final_report(total_stats, unprocessed_videos, chunks_stats)
        
        return len(unprocessed_videos) == 0
    
    async def _get_total_stats(self):
        """è·å–æ€»ä½“ç»Ÿè®¡"""
        query = """
        SELECT 
            COUNT(*) as total_videos,
            COUNT(CASE WHEN processed_at IS NOT NULL THEN 1 END) as processed_videos,
            COUNT(CASE WHEN processed_at IS NULL THEN 1 END) as unprocessed_videos,
            COUNT(CASE WHEN content IS NOT NULL AND content != '' THEN 1 END) as videos_with_content
        FROM pages 
        WHERE url LIKE 'https://www.youtube.com/watch?v=%'
        """
        
        result = await self.db_client.fetch_one(query)
        return dict(result)
    
    async def _get_unprocessed_videos(self):
        """è·å–æœªå¤„ç†çš„è§†é¢‘"""
        query = """
        SELECT url, content IS NOT NULL as has_content
        FROM pages
        WHERE url LIKE 'https://www.youtube.com/watch?v=%'
        AND processed_at IS NULL
        ORDER BY url
        LIMIT 10
        """

        results = await self.db_client.fetch_all(query)
        return [dict(row) for row in results]
    
    async def _get_chunks_stats(self):
        """è·å–chunksç»Ÿè®¡"""
        query = """
        SELECT 
            COUNT(*) as total_chunks,
            COUNT(CASE WHEN embedding IS NOT NULL THEN 1 END) as chunks_with_embedding,
            AVG(LENGTH(content)) as avg_chunk_length,
            MIN(LENGTH(content)) as min_chunk_length,
            MAX(LENGTH(content)) as max_chunk_length
        FROM chunks 
        WHERE url LIKE 'https://www.youtube.com/watch?v=%'
        """
        
        result = await self.db_client.fetch_one(query)
        return dict(result)
    
    async def _get_sample_processed_videos(self, limit=5):
        """è·å–å·²å¤„ç†è§†é¢‘æ ·æœ¬"""
        query = """
        SELECT
            p.url,
            p.processed_at,
            COUNT(c.id) as chunk_count
        FROM pages p
        LEFT JOIN chunks c ON p.url = c.url
        WHERE p.url LIKE 'https://www.youtube.com/watch?v=%'
        AND p.processed_at IS NOT NULL
        GROUP BY p.url, p.processed_at
        ORDER BY p.processed_at DESC
        LIMIT $1
        """

        results = await self.db_client.fetch_all(query, limit)
        return [dict(row) for row in results]
    
    def _generate_final_report(self, total_stats, unprocessed_videos, chunks_stats):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        logger.info("=" * 80)
        logger.info("ğŸŠ YouTubeå­—å¹•å¤„ç†æœ€ç»ˆéªŒè¯æŠ¥å‘Š")
        logger.info("=" * 80)
        
        # æ€»ä½“ç»Ÿè®¡
        logger.info("ğŸ“Š æ€»ä½“å¤„ç†ç»Ÿè®¡:")
        logger.info(f"   æ€»è§†é¢‘æ•°: {total_stats['total_videos']}")
        logger.info(f"   å·²å¤„ç†è§†é¢‘: {total_stats['processed_videos']}")
        logger.info(f"   æœªå¤„ç†è§†é¢‘: {total_stats['unprocessed_videos']}")
        logger.info(f"   æœ‰å†…å®¹è§†é¢‘: {total_stats['videos_with_content']}")
        
        if total_stats['total_videos'] > 0:
            completion_rate = (total_stats['processed_videos'] / total_stats['total_videos']) * 100
            logger.info(f"   å®Œæˆç‡: {completion_rate:.1f}%")
        
        # Chunksç»Ÿè®¡
        logger.info("\nğŸ“¦ Chunkså¤„ç†ç»Ÿè®¡:")
        logger.info(f"   æ€»chunksæ•°: {chunks_stats['total_chunks']}")
        logger.info(f"   æœ‰embeddingçš„chunks: {chunks_stats['chunks_with_embedding']}")
        
        if chunks_stats['total_chunks'] > 0:
            embedding_rate = (chunks_stats['chunks_with_embedding'] / chunks_stats['total_chunks']) * 100
            logger.info(f"   Embeddingå®Œæˆç‡: {embedding_rate:.1f}%")
        
        if chunks_stats['avg_chunk_length']:
            logger.info(f"   å¹³å‡chunké•¿åº¦: {chunks_stats['avg_chunk_length']:.0f} å­—ç¬¦")
            logger.info(f"   æœ€å°chunké•¿åº¦: {chunks_stats['min_chunk_length']} å­—ç¬¦")
            logger.info(f"   æœ€å¤§chunké•¿åº¦: {chunks_stats['max_chunk_length']} å­—ç¬¦")
        
        # æœªå¤„ç†è§†é¢‘
        if unprocessed_videos:
            logger.info(f"\nâš ï¸ å‘ç° {len(unprocessed_videos)} ä¸ªæœªå¤„ç†è§†é¢‘:")
            for video in unprocessed_videos:
                has_content = "æœ‰å†…å®¹" if video['has_content'] else "æ— å†…å®¹"
                logger.info(f"   - {video['url']} ({has_content})")
        else:
            logger.info("\nâœ… æ‰€æœ‰YouTubeè§†é¢‘å·²å®Œæˆå¤„ç†ï¼")
        
        # æœ€ç»ˆç»“è®º
        logger.info("\n" + "=" * 80)
        if len(unprocessed_videos) == 0:
            logger.info("ğŸ‰ YouTubeå­—å¹•å¤„ç†ä»»åŠ¡100%å®Œæˆï¼")
            logger.info("âœ… æ‰€æœ‰è§†é¢‘å·²æˆåŠŸå¤„ç†å¹¶ç”Ÿæˆchunks")
            logger.info("âœ… æ‰€æœ‰chunkså·²å®Œæˆembedding")
            logger.info("âœ… æ•°æ®å·²å‡†å¤‡å°±ç»ªï¼Œå¯ç”¨äºRAGæ£€ç´¢")
        else:
            logger.info("âš ï¸ å¤„ç†æœªå®Œå…¨å®Œæˆ")
            logger.info(f"âŒ è¿˜æœ‰ {len(unprocessed_videos)} ä¸ªè§†é¢‘æœªå¤„ç†")
            logger.info("ğŸ’¡ å»ºè®®é‡æ–°è¿è¡Œå¤„ç†å™¨å®Œæˆå‰©ä½™è§†é¢‘")
        
        logger.info("=" * 80)
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.db_client:
            await self.db_client.close()
            logger.info("ğŸ”’ æ•°æ®åº“è¿æ¥å·²å…³é—­")


async def main():
    """ä¸»å‡½æ•°"""
    verifier = FinalVerification()
    
    try:
        await verifier.initialize()
        
        # æ‰§è¡Œæœ€ç»ˆéªŒè¯
        is_complete = await verifier.verify_completion()
        
        # è·å–å¤„ç†æ ·æœ¬
        logger.info("\nğŸ“‹ æœ€è¿‘å¤„ç†çš„è§†é¢‘æ ·æœ¬:")
        sample_videos = await verifier._get_sample_processed_videos(5)
        for video in sample_videos:
            logger.info(f"   âœ… {video['url']} ({video['chunk_count']} chunks)")
            logger.info(f"      å¤„ç†æ—¶é—´: {video['processed_at']}")
        
        if is_complete:
            logger.info("\nğŸŠ æ­å–œï¼æ‰€æœ‰YouTubeè§†é¢‘å¤„ç†å®Œæˆï¼")
        else:
            logger.info("\nâš ï¸ å¤„ç†å°šæœªå®Œæˆï¼Œè¯·æ£€æŸ¥æœªå¤„ç†çš„è§†é¢‘")
            
    except Exception as e:
        logger.error(f"âŒ éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        
    finally:
        await verifier.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
