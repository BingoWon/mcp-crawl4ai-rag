#!/usr/bin/env python3
"""
éªŒè¯YouTubeå¤„ç†ç»“æœ
"""

import asyncio
import json
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv(project_root / ".env")

from src.database import create_database_client
from src.utils.logger import setup_logger

logger = setup_logger(__name__)


async def verify_results():
    """éªŒè¯YouTubeå¤„ç†ç»“æœ"""
    client = create_database_client()
    await client.initialize()
    
    try:
        # æ£€æŸ¥YouTube chunks
        logger.info('=== YouTube ChunkséªŒè¯ ===')
        youtube_chunks = await client.fetch_all('''
            SELECT url, LENGTH(content) as content_length, 
                   CASE WHEN embedding IS NOT NULL THEN 'YES' ELSE 'NO' END as has_embedding
            FROM chunks 
            WHERE url LIKE 'https://www.youtube.com/watch?v=%'
            ORDER BY url
        ''')
        
        logger.info(f'YouTube chunksæ€»æ•°: {len(youtube_chunks)}')
        for chunk in youtube_chunks:
            logger.info(f'  URL: {chunk["url"]}')
            logger.info(f'  é•¿åº¦: {chunk["content_length"]}å­—ç¬¦, embedding: {chunk["has_embedding"]}')
        
        # æ£€æŸ¥processed_atçŠ¶æ€
        logger.info('\n=== Pageså¤„ç†çŠ¶æ€éªŒè¯ ===')
        processed_pages = await client.fetch_all('''
            SELECT url, 
                   CASE WHEN processed_at IS NOT NULL THEN 'PROCESSED' ELSE 'PENDING' END as status,
                   processed_at
            FROM pages 
            WHERE url LIKE 'https://www.youtube.com/watch?v=%'
            ORDER BY processed_at DESC NULLS LAST
            LIMIT 3
        ''')
        
        for page in processed_pages:
            logger.info(f'  {page["url"]}: {page["status"]}')
            if page["processed_at"]:
                logger.info(f'    å¤„ç†æ—¶é—´: {page["processed_at"]}')
        
        # æ£€æŸ¥chunkå†…å®¹æ ·æœ¬
        logger.info('\n=== Chunkå†…å®¹æ ·æœ¬ ===')
        sample_chunk = await client.fetch_one('''
            SELECT content FROM chunks 
            WHERE url LIKE 'https://www.youtube.com/watch?v=%'
            LIMIT 1
        ''')
        
        if sample_chunk:
            try:
                chunk_data = json.loads(sample_chunk['content'])
                logger.info(f'Context: {chunk_data.get("context", "N/A")}')
                logger.info(f'Contenté¢„è§ˆ: {chunk_data.get("content", "")[:100]}...')
            except:
                logger.info(f'Contenté¢„è§ˆ: {sample_chunk["content"][:100]}...')
        
        # ç»Ÿè®¡ä¿¡æ¯
        logger.info('\n=== ç»Ÿè®¡ä¿¡æ¯ ===')
        stats = await client.fetch_one('''
            SELECT 
                COUNT(*) as total_chunks,
                COUNT(CASE WHEN embedding IS NOT NULL THEN 1 END) as with_embedding,
                AVG(LENGTH(content)) as avg_content_length
            FROM chunks 
            WHERE url LIKE 'https://www.youtube.com/watch?v=%'
        ''')
        
        if stats:
            logger.info(f'æ€»chunks: {stats["total_chunks"]}')
            logger.info(f'æœ‰embedding: {stats["with_embedding"]}')
            logger.info(f'å¹³å‡é•¿åº¦: {stats["avg_content_length"]:.0f}å­—ç¬¦')
        
    finally:
        await client.close()


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ” å¼€å§‹éªŒè¯YouTubeå¤„ç†ç»“æœ...")
    await verify_results()
    logger.info("âœ… éªŒè¯å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())
