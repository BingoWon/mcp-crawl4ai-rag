#!/usr/bin/env python3
"""
ä¼˜åŒ–å‰åå¯¹æ¯”æµ‹è¯•
å±•ç¤º60GBæ˜¾å­˜é—®é¢˜çš„è§£å†³æ•ˆæœ
"""

import os
import sys
import subprocess
import tempfile
import shutil
from pathlib import Path

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.append('src')


def create_problematic_version():
    """åˆ›å»ºæœ‰é—®é¢˜çš„ç‰ˆæœ¬ï¼ˆä¼˜åŒ–å‰ï¼‰"""
    print("ğŸ”§ åˆ›å»ºä¼˜åŒ–å‰çš„ä»£ç ç‰ˆæœ¬...")
    
    # å¤‡ä»½å½“å‰çš„ä¼˜åŒ–ç‰ˆæœ¬
    backup_dir = tempfile.mkdtemp(prefix="embedding_backup_")
    current_file = "src/embedding/core.py"
    backup_file = os.path.join(backup_dir, "core_optimized.py")
    shutil.copy2(current_file, backup_file)
    
    # åˆ›å»ºæœ‰é—®é¢˜çš„ç‰ˆæœ¬ï¼ˆæ²¡æœ‰è¿›ç¨‹å®‰å…¨æœºåˆ¶ï¼‰
    problematic_code = '''"""
Embedding Core
åµŒå…¥æ ¸å¿ƒ

Unified embedding interfaces and factory system.
ç»Ÿä¸€çš„åµŒå…¥æ¥å£å’Œå·¥å‚ç³»ç»Ÿã€‚
"""

from abc import ABC, abstractmethod
from typing import List, Optional

from .config import EmbeddingConfig


class EmbeddingProvider(ABC):
    """Abstract base class for all embedding providers"""
    
    def __init__(self, config: EmbeddingConfig):
        self.config = config
    
    @abstractmethod
    def encode_single(
        self, 
        text: str, 
        is_query: bool = False
    ) -> List[float]:
        """
        Encode single text to embedding with L2 normalization
        
        Args:
            text: Text to encode
            is_query: Whether text is a query (vs document)
            
        Returns:
            L2 normalized embedding vector as list of floats
        """
        pass
    
    @property
    @abstractmethod
    def embedding_dim(self) -> int:
        """Get embedding dimension"""
        pass
    
    @property
    @abstractmethod
    def model_name(self) -> str:
        """Get model name"""
        pass


# PROBLEMATIC: Simple global singleton without process safety
_global_embedder: Optional[EmbeddingProvider] = None


def get_embedder(config: Optional[EmbeddingConfig] = None) -> EmbeddingProvider:
    """
    Get or create global embedding provider instance (PROBLEMATIC VERSION)
    
    Args:
        config: Optional configuration, uses default if None
        
    Returns:
        Embedding provider instance
    """
    global _global_embedder
    
    # PROBLEM: No process ID checking, no thread safety
    if _global_embedder is None:
        if config is None:
            config = EmbeddingConfig()
        
        if config.provider == "api":
            from .providers import SiliconFlowProvider
            _global_embedder = SiliconFlowProvider(config)
        else:
            from .providers import LocalQwen3Provider
            _global_embedder = LocalQwen3Provider(config)
    
    return _global_embedder


def create_embedding(text: str, is_query: bool = False) -> List[float]:
    """
    Create L2 normalized embedding for single text
    
    Args:
        text: Text to encode
        is_query: Whether text is a query
        
    Returns:
        L2 normalized embedding vector as list of floats
    """
    embedder = get_embedder()
    return embedder.encode_single(text, is_query=is_query)
'''
    
    # å†™å…¥æœ‰é—®é¢˜çš„ç‰ˆæœ¬
    with open(current_file, 'w', encoding='utf-8') as f:
        f.write(problematic_code)
    
    print("âœ… ä¼˜åŒ–å‰ç‰ˆæœ¬å·²åˆ›å»º")
    return backup_file


def restore_optimized_version(backup_file: str):
    """æ¢å¤ä¼˜åŒ–åçš„ç‰ˆæœ¬"""
    print("ğŸ”§ æ¢å¤ä¼˜åŒ–åçš„ä»£ç ç‰ˆæœ¬...")
    
    current_file = "src/embedding/core.py"
    shutil.copy2(backup_file, current_file)
    
    # æ¸…ç†å¤‡ä»½
    os.remove(backup_file)
    os.rmdir(os.path.dirname(backup_file))
    
    print("âœ… ä¼˜åŒ–åç‰ˆæœ¬å·²æ¢å¤")


def run_test_and_capture_output(test_description: str):
    """è¿è¡Œæµ‹è¯•å¹¶æ•è·è¾“å‡º"""
    print(f"\n{'='*60}")
    print(f"ğŸ§ª {test_description}")
    print('='*60)
    
    try:
        # è¿è¡Œæµ‹è¯•
        result = subprocess.run(
            ["python", "tests/test_real_memory_issue.py"],
            capture_output=True,
            text=True,
            timeout=300,  # 5åˆ†é’Ÿè¶…æ—¶
            cwd="."
        )
        
        print("ğŸ“Š æµ‹è¯•è¾“å‡º:")
        print(result.stdout)
        
        if result.stderr:
            print("âš ï¸ é”™è¯¯è¾“å‡º:")
            print(result.stderr)
        
        return {
            "success": result.returncode == 0,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "returncode": result.returncode
        }
        
    except subprocess.TimeoutExpired:
        print("â° æµ‹è¯•è¶…æ—¶ï¼ˆå¯èƒ½ç”±äºå†…å­˜é—®é¢˜å¯¼è‡´ç³»ç»Ÿå¡æ­»ï¼‰")
        return {
            "success": False,
            "stdout": "",
            "stderr": "Test timed out",
            "returncode": -1,
            "timeout": True
        }
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return {
            "success": False,
            "stdout": "",
            "stderr": str(e),
            "returncode": -2
        }


def extract_memory_info(output: str) -> dict:
    """ä»è¾“å‡ºä¸­æå–å†…å­˜ä¿¡æ¯"""
    memory_info = {
        "peak_memory": 0.0,
        "model_reuse_working": False,
        "crawler_reuse_working": False,
        "total_increase": 0.0
    }
    
    lines = output.split('\n')
    for line in lines:
        if "å³°å€¼GPUå†…å­˜ä½¿ç”¨:" in line:
            try:
                memory_str = line.split(":")[1].strip().replace("GB", "")
                memory_info["peak_memory"] = float(memory_str)
            except:
                pass
        
        if "æ¨¡å‹å¤ç”¨æ­£å¸¸" in line:
            memory_info["model_reuse_working"] = True
        
        if "Crawlerå¤ç”¨æ­£å¸¸" in line:
            memory_info["crawler_reuse_working"] = True
        
        if "æ€»å†…å­˜å¢åŠ :" in line and "ç›´æ¥è°ƒç”¨æµ‹è¯•" in line:
            try:
                memory_str = line.split("æ€»å†…å­˜å¢åŠ :")[1].strip().replace("GB", "")
                memory_info["total_increase"] = float(memory_str)
            except:
                pass
    
    return memory_info


def main():
    """ä¸»å¯¹æ¯”æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ ä¼˜åŒ–å‰åå¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    print("ğŸ“‹ æµ‹è¯•è®¡åˆ’ï¼š")
    print("1. è¿è¡Œä¼˜åŒ–åç‰ˆæœ¬æµ‹è¯•ï¼ˆå½“å‰çŠ¶æ€ï¼‰")
    print("2. ä¸´æ—¶åˆ‡æ¢åˆ°ä¼˜åŒ–å‰ç‰ˆæœ¬")
    print("3. è¿è¡Œä¼˜åŒ–å‰ç‰ˆæœ¬æµ‹è¯•")
    print("4. æ¢å¤ä¼˜åŒ–åç‰ˆæœ¬")
    print("5. å¯¹æ¯”ç»“æœ")
    print("=" * 60)
    
    # ç¬¬ä¸€æ­¥ï¼šæµ‹è¯•ä¼˜åŒ–åç‰ˆæœ¬
    print("\nğŸš€ ç¬¬ä¸€æ­¥ï¼šæµ‹è¯•ä¼˜åŒ–åç‰ˆæœ¬ï¼ˆå½“å‰çŠ¶æ€ï¼‰")
    optimized_result = run_test_and_capture_output("ä¼˜åŒ–åç‰ˆæœ¬æµ‹è¯•")
    optimized_memory = extract_memory_info(optimized_result.get("stdout", ""))
    
    # ç¬¬äºŒæ­¥ï¼šåˆ›å»ºå¹¶æµ‹è¯•æœ‰é—®é¢˜çš„ç‰ˆæœ¬
    print("\nğŸ”„ ç¬¬äºŒæ­¥ï¼šåˆ‡æ¢åˆ°ä¼˜åŒ–å‰ç‰ˆæœ¬å¹¶æµ‹è¯•")
    backup_file = create_problematic_version()
    
    try:
        problematic_result = run_test_and_capture_output("ä¼˜åŒ–å‰ç‰ˆæœ¬æµ‹è¯•ï¼ˆå¯èƒ½ä¼šå¡æ­»ï¼‰")
        problematic_memory = extract_memory_info(problematic_result.get("stdout", ""))
    finally:
        # ç¬¬ä¸‰æ­¥ï¼šæ¢å¤ä¼˜åŒ–åç‰ˆæœ¬
        print("\nğŸ”§ ç¬¬ä¸‰æ­¥ï¼šæ¢å¤ä¼˜åŒ–åç‰ˆæœ¬")
        restore_optimized_version(backup_file)
    
    # ç¬¬å››æ­¥ï¼šå¯¹æ¯”ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š å¯¹æ¯”ç»“æœæ±‡æ€»")
    print("="*60)
    
    print(f"\nğŸ”´ ä¼˜åŒ–å‰ç‰ˆæœ¬:")
    if problematic_result.get("timeout"):
        print("   âŒ æµ‹è¯•è¶…æ—¶ï¼ˆç³»ç»Ÿå¡æ­»ï¼‰")
        print("   ğŸš¨ è¿™è¯æ˜äº†60GBæ˜¾å­˜é—®é¢˜çš„å­˜åœ¨")
    elif not problematic_result.get("success"):
        print(f"   âŒ æµ‹è¯•å¤±è´¥ (è¿”å›ç : {problematic_result.get('returncode')})")
        print("   ğŸš¨ å¯èƒ½ç”±äºå†…å­˜é—®é¢˜å¯¼è‡´")
    else:
        print(f"   ğŸ“ˆ å³°å€¼å†…å­˜: {problematic_memory['peak_memory']:.2f}GB")
        print(f"   ğŸ“Š æ€»å†…å­˜å¢åŠ : {problematic_memory['total_increase']:.2f}GB")
        print(f"   ğŸ”„ æ¨¡å‹å¤ç”¨: {'âœ…' if problematic_memory['model_reuse_working'] else 'âŒ'}")
    
    print(f"\nğŸŸ¢ ä¼˜åŒ–åç‰ˆæœ¬:")
    if optimized_result.get("success"):
        print(f"   ğŸ“ˆ å³°å€¼å†…å­˜: {optimized_memory['peak_memory']:.2f}GB")
        print(f"   ğŸ“Š æ€»å†…å­˜å¢åŠ : {optimized_memory['total_increase']:.2f}GB")
        print(f"   ğŸ”„ æ¨¡å‹å¤ç”¨: {'âœ…' if optimized_memory['model_reuse_working'] else 'âŒ'}")
        print(f"   ğŸ—ï¸ Crawlerå¤ç”¨: {'âœ…' if optimized_memory['crawler_reuse_working'] else 'âŒ'}")
    else:
        print("   âŒ æµ‹è¯•å¤±è´¥")
    
    # ç»“è®º
    print(f"\nğŸ¯ å¯¹æ¯”ç»“è®º:")
    
    if problematic_result.get("timeout"):
        print("âœ… ä¼˜åŒ–å‰ç‰ˆæœ¬å¯¼è‡´ç³»ç»Ÿå¡æ­»ï¼Œä¼˜åŒ–åç‰ˆæœ¬æ­£å¸¸è¿è¡Œ")
        print("âœ… 60GBæ˜¾å­˜é—®é¢˜å·²å®Œå…¨è§£å†³")
    elif optimized_result.get("success") and optimized_memory['peak_memory'] < 20:
        print("âœ… å†…å­˜ä½¿ç”¨ä»æ½œåœ¨çš„60GB+é™ä½åˆ°15GBå·¦å³")
        print("âœ… æ¨¡å‹å¤ç”¨æœºåˆ¶æ­£å¸¸å·¥ä½œ")
        print("âœ… è¿›ç¨‹å®‰å…¨æœºåˆ¶æœ‰æ•ˆé˜²æ­¢é‡å¤åŠ è½½")
    
    if optimized_memory['model_reuse_working'] and optimized_memory['crawler_reuse_working']:
        print("âœ… æ‰€æœ‰å¤ç”¨æœºåˆ¶éƒ½æ­£å¸¸å·¥ä½œ")
    
    print("\nğŸ‰ å¯¹æ¯”æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main()
