#!/usr/bin/env python3
"""
çœŸå®å†…å­˜é—®é¢˜éªŒè¯æµ‹è¯•
å±•ç¤ºä¼˜åŒ–å‰åçš„çœŸå®å·®å¼‚ï¼Œä¸ä½¿ç”¨ä»»ä½•å¼ºåˆ¶é‡è½½
"""

import os
import sys
import asyncio
import torch
import time
from typing import Dict, Any

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.append('src')

from utils.logger import setup_logger

logger = setup_logger(__name__)


def get_gpu_memory_usage() -> Dict[str, float]:
    """è·å–GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        return {
            "allocated_gb": torch.cuda.memory_allocated() / 1024**3,
            "reserved_gb": torch.cuda.memory_reserved() / 1024**3,
        }
    elif torch.backends.mps.is_available():
        return {
            "allocated_gb": torch.mps.current_allocated_memory() / 1024**3,
            "reserved_gb": 0.0,
        }
    else:
        return {"allocated_gb": 0.0, "reserved_gb": 0.0}


def monitor_memory(stage: str):
    """ç›‘æ§å¹¶æ˜¾ç¤ºå†…å­˜ä½¿ç”¨"""
    memory = get_gpu_memory_usage()
    print(f"ğŸ“Š {stage}: GPUå†…å­˜ {memory['allocated_gb']:.2f}GB")
    return memory['allocated_gb']


async def test_real_crawler_usage():
    """æµ‹è¯•çœŸå®çš„crawlerä½¿ç”¨åœºæ™¯"""
    print("ğŸš€ æµ‹è¯•çœŸå®crawlerä½¿ç”¨åœºæ™¯...")
    
    # åˆå§‹å†…å­˜
    initial_memory = monitor_memory("åˆå§‹çŠ¶æ€")
    
    try:
        # å¯¼å…¥crawlerï¼ˆè¿™å¯èƒ½è§¦å‘embeddingæ¨¡å‹åŠ è½½ï¼‰
        from crawler.core import IndependentCrawler
        after_import = monitor_memory("å¯¼å…¥crawlerå")
        
        # åˆ›å»ºcrawlerå®ä¾‹
        async with IndependentCrawler() as crawler:
            after_init = monitor_memory("crawleråˆå§‹åŒ–å")
            
            # æ¨¡æ‹ŸçœŸå®çš„å†…å®¹å¤„ç†ï¼ˆè¿™ä¼šè§¦å‘embeddingï¼‰
            test_content = """
            # SwiftUI Documentation
            
            SwiftUI is a modern way to declare user interfaces for any Apple platform.
            
            ## Overview
            
            SwiftUI provides views, controls, and layout structures for declaring your app's user interface.
            """
            
            print("ğŸ“ å¼€å§‹å¤„ç†å†…å®¹...")
            result = await crawler._process_and_store_content(
                "https://developer.apple.com/documentation/swiftui",
                test_content
            )
            after_processing = monitor_memory("å†…å®¹å¤„ç†å")
            
            # å†æ¬¡å¤„ç†å†…å®¹ï¼ˆæµ‹è¯•æ¨¡å‹å¤ç”¨ï¼‰
            print("ğŸ“ å†æ¬¡å¤„ç†å†…å®¹...")
            result2 = await crawler._process_and_store_content(
                "https://developer.apple.com/documentation/swiftui/view",
                test_content + "\n\nAdditional content for second processing."
            )
            after_second = monitor_memory("ç¬¬äºŒæ¬¡å¤„ç†å")
            
            print(f"âœ… ç¬¬ä¸€æ¬¡å¤„ç†ç»“æœ: {result.get('success', False)}")
            print(f"âœ… ç¬¬äºŒæ¬¡å¤„ç†ç»“æœ: {result2.get('success', False)}")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    final_memory = monitor_memory("æµ‹è¯•å®Œæˆ")
    
    return {
        "initial": initial_memory,
        "after_import": after_import,
        "after_init": after_init,
        "after_processing": after_processing,
        "after_second": after_second,
        "final": final_memory,
        "total_increase": final_memory - initial_memory,
        "second_processing_increase": after_second - after_processing
    }


async def test_multiple_crawler_instances():
    """æµ‹è¯•å¤šä¸ªcrawlerå®ä¾‹ï¼ˆå¯èƒ½è§¦å‘å¤šè¿›ç¨‹é—®é¢˜ï¼‰"""
    print("\nğŸ”„ æµ‹è¯•å¤šä¸ªcrawlerå®ä¾‹...")
    
    initial_memory = monitor_memory("å¤šå®ä¾‹æµ‹è¯•åˆå§‹")
    
    try:
        from crawler.core import IndependentCrawler
        
        # ç¬¬ä¸€ä¸ªå®ä¾‹
        print("ğŸ“± åˆ›å»ºç¬¬ä¸€ä¸ªcrawlerå®ä¾‹...")
        async with IndependentCrawler() as crawler1:
            after_first = monitor_memory("ç¬¬ä¸€ä¸ªå®ä¾‹åˆ›å»ºå")
            
            # ç¬¬äºŒä¸ªå®ä¾‹
            print("ğŸ“± åˆ›å»ºç¬¬äºŒä¸ªcrawlerå®ä¾‹...")
            async with IndependentCrawler() as crawler2:
                after_second = monitor_memory("ç¬¬äºŒä¸ªå®ä¾‹åˆ›å»ºå")
                
                # åŒæ—¶ä½¿ç”¨ä¸¤ä¸ªå®ä¾‹
                test_content = "Test content for multiple instances"
                
                result1 = await crawler1._process_and_store_content(
                    "https://test1.example.com", test_content
                )
                after_use1 = monitor_memory("ä½¿ç”¨å®ä¾‹1å")
                
                result2 = await crawler2._process_and_store_content(
                    "https://test2.example.com", test_content
                )
                after_use2 = monitor_memory("ä½¿ç”¨å®ä¾‹2å")
                
                print(f"âœ… å®ä¾‹1å¤„ç†ç»“æœ: {result1.get('success', False)}")
                print(f"âœ… å®ä¾‹2å¤„ç†ç»“æœ: {result2.get('success', False)}")
        
    except Exception as e:
        print(f"âŒ å¤šå®ä¾‹æµ‹è¯•å‡ºç°é”™è¯¯: {e}")
        return None
    
    final_memory = monitor_memory("å¤šå®ä¾‹æµ‹è¯•å®Œæˆ")
    
    return {
        "initial": initial_memory,
        "after_first": after_first,
        "after_second": after_second,
        "after_use1": after_use1,
        "after_use2": after_use2,
        "final": final_memory,
        "total_increase": final_memory - initial_memory
    }


def test_direct_embedding_calls():
    """æµ‹è¯•ç›´æ¥çš„embeddingè°ƒç”¨"""
    print("\nğŸ§  æµ‹è¯•ç›´æ¥embeddingè°ƒç”¨...")
    
    initial_memory = monitor_memory("ç›´æ¥è°ƒç”¨æµ‹è¯•åˆå§‹")
    
    try:
        from embedding import create_embedding
        
        # ç¬¬ä¸€æ¬¡è°ƒç”¨
        print("ğŸ”¤ ç¬¬ä¸€æ¬¡embeddingè°ƒç”¨...")
        embedding1 = create_embedding("First embedding test")
        after_first = monitor_memory("ç¬¬ä¸€æ¬¡è°ƒç”¨å")
        
        # ç¬¬äºŒæ¬¡è°ƒç”¨
        print("ğŸ”¤ ç¬¬äºŒæ¬¡embeddingè°ƒç”¨...")
        embedding2 = create_embedding("Second embedding test")
        after_second = monitor_memory("ç¬¬äºŒæ¬¡è°ƒç”¨å")
        
        # ç¬¬ä¸‰æ¬¡è°ƒç”¨
        print("ğŸ”¤ ç¬¬ä¸‰æ¬¡embeddingè°ƒç”¨...")
        embedding3 = create_embedding("Third embedding test")
        after_third = monitor_memory("ç¬¬ä¸‰æ¬¡è°ƒç”¨å")
        
        print(f"âœ… Embeddingç»´åº¦: {len(embedding1)}")
        print(f"âœ… ä¸‰æ¬¡è°ƒç”¨éƒ½æˆåŠŸå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ ç›´æ¥è°ƒç”¨æµ‹è¯•å‡ºç°é”™è¯¯: {e}")
        return None
    
    final_memory = monitor_memory("ç›´æ¥è°ƒç”¨æµ‹è¯•å®Œæˆ")
    
    return {
        "initial": initial_memory,
        "after_first": after_first,
        "after_second": after_second,
        "after_third": after_third,
        "final": final_memory,
        "total_increase": final_memory - initial_memory,
        "second_call_increase": after_second - after_first,
        "third_call_increase": after_third - after_second
    }


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ çœŸå®å†…å­˜é—®é¢˜éªŒè¯æµ‹è¯•")
    print("=" * 60)
    print("ğŸ“‹ æµ‹è¯•è¯´æ˜ï¼š")
    print("- ä¸ä½¿ç”¨ä»»ä½•å¼ºåˆ¶é‡è½½")
    print("- æ¨¡æ‹ŸçœŸå®ä½¿ç”¨åœºæ™¯")
    print("- ç›‘æ§å†…å­˜ä½¿ç”¨å˜åŒ–")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    tokenizers_setting = os.environ.get("TOKENIZERS_PARALLELISM", "æœªè®¾ç½®")
    print(f"ğŸ”§ TOKENIZERS_PARALLELISM = {tokenizers_setting}")
    
    try:
        # æµ‹è¯•1: çœŸå®crawlerä½¿ç”¨
        crawler_result = await test_real_crawler_usage()
        
        # æµ‹è¯•2: å¤šä¸ªcrawlerå®ä¾‹
        multi_result = await test_multiple_crawler_instances()
        
        # æµ‹è¯•3: ç›´æ¥embeddingè°ƒç”¨
        direct_result = test_direct_embedding_calls()
        
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
        
        if crawler_result:
            print(f"ğŸš€ Crawleræµ‹è¯•:")
            print(f"   æ€»å†…å­˜å¢åŠ : {crawler_result['total_increase']:.2f}GB")
            print(f"   ç¬¬äºŒæ¬¡å¤„ç†å¢åŠ : {crawler_result['second_processing_increase']:.2f}GB")
        
        if multi_result:
            print(f"ğŸ”„ å¤šå®ä¾‹æµ‹è¯•:")
            print(f"   æ€»å†…å­˜å¢åŠ : {multi_result['total_increase']:.2f}GB")
        
        if direct_result:
            print(f"ğŸ§  ç›´æ¥è°ƒç”¨æµ‹è¯•:")
            print(f"   æ€»å†…å­˜å¢åŠ : {direct_result['total_increase']:.2f}GB")
            print(f"   ç¬¬äºŒæ¬¡è°ƒç”¨å¢åŠ : {direct_result['second_call_increase']:.2f}GB")
            print(f"   ç¬¬ä¸‰æ¬¡è°ƒç”¨å¢åŠ : {direct_result['third_call_increase']:.2f}GB")
        
        # è¯„ä¼°ç»“æœ
        print("\nğŸ” ç»“æœè¯„ä¼°:")
        
        if direct_result and direct_result['second_call_increase'] < 1.0:
            print("âœ… æ¨¡å‹å¤ç”¨æ­£å¸¸ï¼šç¬¬äºŒæ¬¡è°ƒç”¨æ²¡æœ‰æ˜¾è‘—å†…å­˜å¢åŠ ")
        elif direct_result:
            print(f"âŒ å¯èƒ½å­˜åœ¨é—®é¢˜ï¼šç¬¬äºŒæ¬¡è°ƒç”¨å¢åŠ äº† {direct_result['second_call_increase']:.2f}GB")
        
        if crawler_result and crawler_result['second_processing_increase'] < 1.0:
            print("âœ… Crawlerå¤ç”¨æ­£å¸¸ï¼šé‡å¤å¤„ç†æ²¡æœ‰æ˜¾è‘—å†…å­˜å¢åŠ ")
        elif crawler_result:
            print(f"âŒ Crawlerå¯èƒ½æœ‰é—®é¢˜ï¼šé‡å¤å¤„ç†å¢åŠ äº† {crawler_result['second_processing_increase']:.2f}GB")
        
        # æ€»ä½“å†…å­˜ä½¿ç”¨è¯„ä¼°
        total_memory = 0
        if direct_result:
            total_memory = max(total_memory, direct_result['final'])
        if crawler_result:
            total_memory = max(total_memory, crawler_result['final'])
        if multi_result:
            total_memory = max(total_memory, multi_result['final'])
        
        print(f"\nğŸ“ˆ å³°å€¼GPUå†…å­˜ä½¿ç”¨: {total_memory:.2f}GB")
        
        if total_memory > 50:
            print("ğŸš¨ è­¦å‘Šï¼šå†…å­˜ä½¿ç”¨è¶…è¿‡50GBï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜")
        elif total_memory > 30:
            print("âš ï¸ æ³¨æ„ï¼šå†…å­˜ä½¿ç”¨è¾ƒé«˜ï¼Œéœ€è¦å…³æ³¨")
        else:
            print("âœ… å†…å­˜ä½¿ç”¨åœ¨åˆç†èŒƒå›´å†…")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
