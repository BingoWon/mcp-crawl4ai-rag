#!/usr/bin/env python3
"""
Content Length Distribution Analyzer
åˆ†æžchunksè¡¨ä¸­contentå­—æ®µé•¿åº¦åˆ†å¸ƒçš„å¯è§†åŒ–å·¥å…·

åŠŸèƒ½ï¼š
- æŸ¥è¯¢æ•°æ®åº“chunksè¡¨
- åˆ†æžcontentå­—æ®µé•¿åº¦åˆ†å¸ƒ
- ç”Ÿæˆç›´æ–¹å›¾å’Œç»Ÿè®¡å›¾è¡¨
- ä¿å­˜åˆ†æžç»“æžœ
"""

import asyncio
import sys
import os
from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from datetime import datetime
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

# åŠ è½½çŽ¯å¢ƒå˜é‡
load_dotenv(project_root / ".env")

from src.database import create_database_client
from src.utils.logger import setup_logger

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

logger = setup_logger(__name__)


class ContentLengthAnalyzer:
    """Contenté•¿åº¦åˆ†å¸ƒåˆ†æžå™¨"""
    
    def __init__(self):
        self.db_client = None
        self.content_lengths = []
        self.stats = {}
        
    async def initialize(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿žæŽ¥"""
        logger.info("ðŸ”— åˆå§‹åŒ–æ•°æ®åº“è¿žæŽ¥...")
        self.db_client = create_database_client()
        await self.db_client.initialize()
        logger.info("âœ… æ•°æ®åº“è¿žæŽ¥æˆåŠŸ")
        
    async def fetch_content_lengths(self):
        """èŽ·å–æ‰€æœ‰chunksçš„contenté•¿åº¦"""
        logger.info("ðŸ“Š æŸ¥è¯¢chunksè¡¨contenté•¿åº¦...")
        
        # æŸ¥è¯¢æ‰€æœ‰chunksçš„contenté•¿åº¦
        query = """
        SELECT 
            LENGTH(content) as content_length,
            url,
            SUBSTRING(content, 1, 100) as content_preview
        FROM chunks 
        WHERE content IS NOT NULL AND content != ''
        ORDER BY LENGTH(content) DESC
        """
        
        results = await self.db_client.fetch_all(query)
        logger.info(f"ðŸ“ˆ èŽ·å–åˆ° {len(results)} æ¡è®°å½•")
        
        # æå–é•¿åº¦æ•°æ®
        self.content_lengths = [row['content_length'] for row in results]
        
        # ä¿å­˜è¯¦ç»†æ•°æ®ç”¨äºŽåˆ†æž
        self.detailed_data = results
        
        return results
        
    def calculate_statistics(self):
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        if not self.content_lengths:
            logger.warning("âš ï¸ æ²¡æœ‰æ•°æ®å¯ä¾›åˆ†æž")
            return
            
        lengths = np.array(self.content_lengths)
        
        self.stats = {
            'total_count': len(lengths),
            'min_length': int(np.min(lengths)),
            'max_length': int(np.max(lengths)),
            'mean_length': float(np.mean(lengths)),
            'median_length': float(np.median(lengths)),
            'std_length': float(np.std(lengths)),
            'q25': float(np.percentile(lengths, 25)),
            'q75': float(np.percentile(lengths, 75)),
            'q90': float(np.percentile(lengths, 90)),
            'q95': float(np.percentile(lengths, 95)),
            'q99': float(np.percentile(lengths, 99))
        }
        
        logger.info("ðŸ“Š ç»Ÿè®¡ä¿¡æ¯è®¡ç®—å®Œæˆ")
        
    def create_visualizations(self):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        if not self.content_lengths:
            logger.warning("âš ï¸ æ²¡æœ‰æ•°æ®å¯ä¾›å¯è§†åŒ–")
            return
            
        # åˆ›å»ºå›¾è¡¨ç›®å½•
        output_dir = Path(__file__).parent / "content_analysis_output"
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. åŸºç¡€ç›´æ–¹å›¾
        self._create_histogram(output_dir, timestamp)
        
        # 2. ç®±çº¿å›¾
        self._create_boxplot(output_dir, timestamp)
        
        # 3. ç´¯ç§¯åˆ†å¸ƒå›¾
        self._create_cumulative_distribution(output_dir, timestamp)
        
        # 4. åˆ†æ®µç»Ÿè®¡å›¾
        self._create_length_segments_chart(output_dir, timestamp)
        
        logger.info(f"ðŸ“ˆ å›¾è¡¨å·²ä¿å­˜åˆ°: {output_dir}")
        
    def _create_histogram(self, output_dir, timestamp):
        """åˆ›å»ºç›´æ–¹å›¾"""
        plt.figure(figsize=(12, 8))
        
        # ä½¿ç”¨åˆé€‚çš„binsæ•°é‡
        bins = min(50, len(set(self.content_lengths)))
        
        plt.hist(self.content_lengths, bins=bins, alpha=0.7, color='skyblue', edgecolor='black')
        plt.title(f'Content Length Distribution\næ€»è®°å½•æ•°: {self.stats["total_count"]}', fontsize=16)
        plt.xlabel('Content Length (characters)', fontsize=12)
        plt.ylabel('Frequency', fontsize=12)
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_text = f"""ç»Ÿè®¡ä¿¡æ¯:
å¹³å‡å€¼: {self.stats['mean_length']:.0f}
ä¸­ä½æ•°: {self.stats['median_length']:.0f}
æ ‡å‡†å·®: {self.stats['std_length']:.0f}
æœ€å°å€¼: {self.stats['min_length']}
æœ€å¤§å€¼: {self.stats['max_length']}"""
        
        plt.text(0.7, 0.7, stats_text, transform=plt.gca().transAxes, 
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray", alpha=0.8),
                fontsize=10, verticalalignment='top')
        
        plt.tight_layout()
        plt.savefig(output_dir / f"content_length_histogram_{timestamp}.png", dpi=300, bbox_inches='tight')
        plt.close()
        
    def _create_boxplot(self, output_dir, timestamp):
        """åˆ›å»ºç®±çº¿å›¾"""
        plt.figure(figsize=(10, 6))
        
        box_plot = plt.boxplot(self.content_lengths, vert=True, patch_artist=True)
        box_plot['boxes'][0].set_facecolor('lightblue')
        
        plt.title('Content Length Box Plot', fontsize=16)
        plt.ylabel('Content Length (characters)', fontsize=12)
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ å››åˆ†ä½æ•°æ ‡æ³¨
        quartiles_text = f"""å››åˆ†ä½æ•°:
Q1 (25%): {self.stats['q25']:.0f}
Q2 (50%): {self.stats['median_length']:.0f}
Q3 (75%): {self.stats['q75']:.0f}
Q90: {self.stats['q90']:.0f}
Q95: {self.stats['q95']:.0f}
Q99: {self.stats['q99']:.0f}"""
        
        plt.text(1.1, 0.5, quartiles_text, transform=plt.gca().transAxes,
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow", alpha=0.8),
                fontsize=10, verticalalignment='center')
        
        plt.tight_layout()
        plt.savefig(output_dir / f"content_length_boxplot_{timestamp}.png", dpi=300, bbox_inches='tight')
        plt.close()
        
    def _create_cumulative_distribution(self, output_dir, timestamp):
        """åˆ›å»ºç´¯ç§¯åˆ†å¸ƒå›¾"""
        plt.figure(figsize=(12, 8))
        
        sorted_lengths = np.sort(self.content_lengths)
        cumulative_prob = np.arange(1, len(sorted_lengths) + 1) / len(sorted_lengths)
        
        plt.plot(sorted_lengths, cumulative_prob, linewidth=2, color='darkblue')
        plt.title('Cumulative Distribution of Content Lengths', fontsize=16)
        plt.xlabel('Content Length (characters)', fontsize=12)
        plt.ylabel('Cumulative Probability', fontsize=12)
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ å…³é”®ç™¾åˆ†ä½æ•°çº¿
        percentiles = [25, 50, 75, 90, 95, 99]
        colors = ['red', 'orange', 'green', 'purple', 'brown', 'pink']
        
        for p, color in zip(percentiles, colors):
            value = np.percentile(self.content_lengths, p)
            plt.axvline(x=value, color=color, linestyle='--', alpha=0.7, 
                       label=f'P{p}: {value:.0f}')
        
        plt.legend()
        plt.tight_layout()
        plt.savefig(output_dir / f"content_length_cumulative_{timestamp}.png", dpi=300, bbox_inches='tight')
        plt.close()
        
    def _create_length_segments_chart(self, output_dir, timestamp):
        """åˆ›å»ºé•¿åº¦åˆ†æ®µç»Ÿè®¡å›¾"""
        plt.figure(figsize=(12, 8))
        
        # å®šä¹‰é•¿åº¦åŒºé—´
        segments = [
            (0, 500, "Very Short (0-500)"),
            (501, 1000, "Short (501-1000)"),
            (1001, 2000, "Medium (1001-2000)"),
            (2001, 3000, "Long (2001-3000)"),
            (3001, 4000, "Long+ (3001-4000)"),
            (4001, 5000, "Very Long (4001-5000)"),
            (5001, 10000, "Very Long+ (5001-10000)"),
            (10001, float('inf'), "Extremely Long (10000+)")
        ]
        
        segment_counts = []
        segment_labels = []
        
        for min_len, max_len, label in segments:
            if max_len == float('inf'):
                count = sum(1 for length in self.content_lengths if length >= min_len)
            else:
                count = sum(1 for length in self.content_lengths 
                           if min_len <= length <= max_len)
            segment_counts.append(count)
            segment_labels.append(f"{label}\n({count} chunks)")
        
        # åˆ›å»ºé¥¼å›¾
        plt.subplot(1, 2, 1)
        colors = plt.cm.Set3(np.linspace(0, 1, len(segment_counts)))
        plt.pie(segment_counts, labels=segment_labels, autopct='%1.1f%%', 
                colors=colors, startangle=90)
        plt.title('Content Length Distribution by Segments', fontsize=14)
        
        # åˆ›å»ºæŸ±çŠ¶å›¾
        plt.subplot(1, 2, 2)
        bars = plt.bar(range(len(segment_counts)), segment_counts, color=colors)
        plt.title('Content Length Segments Count', fontsize=14)
        plt.xlabel('Length Segments', fontsize=12)
        plt.ylabel('Count', fontsize=12)
        plt.xticks(range(len(segment_labels)), 
                  [label.split('\n')[0] for label in segment_labels], 
                  rotation=45, ha='right')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, count in zip(bars, segment_counts):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(segment_counts)*0.01,
                    str(count), ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig(output_dir / f"content_length_segments_{timestamp}.png", dpi=300, bbox_inches='tight')
        plt.close()
        
    def save_analysis_report(self):
        """ä¿å­˜åˆ†æžæŠ¥å‘Š"""
        output_dir = Path(__file__).parent / "content_analysis_output"
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = output_dir / f"content_analysis_report_{timestamp}.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("Content Length Distribution Analysis Report\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"åˆ†æžæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("åŸºç¡€ç»Ÿè®¡ä¿¡æ¯:\n")
            f.write("-" * 20 + "\n")
            for key, value in self.stats.items():
                if isinstance(value, float):
                    f.write(f"{key}: {value:.2f}\n")
                else:
                    f.write(f"{key}: {value}\n")

            f.write("\nç™¾åˆ†ä½æ•°è§£é‡Š:\n")
            f.write("-" * 20 + "\n")
            f.write(f"Q25 ({self.stats['q25']:.0f}): 25%çš„chunksé•¿åº¦ â‰¤ {self.stats['q25']:.0f}å­—ç¬¦\n")
            f.write(f"Q75 ({self.stats['q75']:.0f}): 75%çš„chunksé•¿åº¦ â‰¤ {self.stats['q75']:.0f}å­—ç¬¦\n")
            f.write(f"Q90 ({self.stats['q90']:.0f}): 90%çš„chunksé•¿åº¦ â‰¤ {self.stats['q90']:.0f}å­—ç¬¦\n")
            f.write(f"Q95 ({self.stats['q95']:.0f}): 95%çš„chunksé•¿åº¦ â‰¤ {self.stats['q95']:.0f}å­—ç¬¦\n")
            f.write(f"Q99 ({self.stats['q99']:.0f}): 99%çš„chunksé•¿åº¦ â‰¤ {self.stats['q99']:.0f}å­—ç¬¦\n")
            f.write("è¯´æ˜Ž: Q25-Q75åŒºé—´åŒ…å«50%çš„æ•°æ®ï¼Œæ˜¯æ ¸å¿ƒåˆ†å¸ƒåŒº\n")
            
            f.write("\né•¿åº¦åˆ†æ®µç»Ÿè®¡:\n")
            f.write("-" * 20 + "\n")
            segments = [
                (0, 500, "Very Short"),
                (501, 1000, "Short"),
                (1001, 2000, "Medium"),
                (2001, 3000, "Long"),
                (3001, 4000, "Long+"),
                (4001, 5000, "Very Long"),
                (5001, 10000, "Very Long+"),
                (10001, float('inf'), "Extremely Long")
            ]
            
            total_chunks = len(self.content_lengths)
            for min_len, max_len, label in segments:
                if max_len == float('inf'):
                    count = sum(1 for length in self.content_lengths if length >= min_len)
                    percentage = (count / total_chunks) * 100
                    f.write(f"{label} ({min_len}+): {count} chunks ({percentage:.2f}%)\n")
                else:
                    count = sum(1 for length in self.content_lengths
                               if min_len <= length <= max_len)
                    percentage = (count / total_chunks) * 100
                    f.write(f"{label} ({min_len}-{max_len}): {count} chunks ({percentage:.2f}%)\n")
            
            # æ·»åŠ æœ€é•¿å’Œæœ€çŸ­çš„å‡ ä¸ªç¤ºä¾‹
            f.write("\næœ€é•¿å†…å®¹ç¤ºä¾‹ (å‰5ä¸ª):\n")
            f.write("-" * 30 + "\n")
            sorted_data = sorted(self.detailed_data, key=lambda x: x['content_length'], reverse=True)
            for i, item in enumerate(sorted_data[:5]):
                f.write(f"{i+1}. é•¿åº¦: {item['content_length']}, URL: {item['url']}\n")
                f.write(f"   é¢„è§ˆ: {item['content_preview']}...\n\n")
            
            f.write("\næœ€çŸ­å†…å®¹ç¤ºä¾‹ (å‰5ä¸ª):\n")
            f.write("-" * 30 + "\n")
            for i, item in enumerate(sorted_data[-5:]):
                f.write(f"{i+1}. é•¿åº¦: {item['content_length']}, URL: {item['url']}\n")
                f.write(f"   é¢„è§ˆ: {item['content_preview']}...\n\n")
        
        logger.info(f"ðŸ“„ åˆ†æžæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
    async def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æžæµç¨‹"""
        try:
            await self.initialize()
            await self.fetch_content_lengths()
            self.calculate_statistics()
            self.create_visualizations()
            self.save_analysis_report()
            
            logger.info("âœ… Contenté•¿åº¦åˆ†å¸ƒåˆ†æžå®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ åˆ†æžè¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯: {e}")
            raise
        finally:
            if self.db_client:
                await self.db_client.close()


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ðŸš€ å¼€å§‹Contenté•¿åº¦åˆ†å¸ƒåˆ†æž...")
    
    analyzer = ContentLengthAnalyzer()
    await analyzer.run_analysis()
    
    logger.info("ðŸŽ‰ åˆ†æžå®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())
