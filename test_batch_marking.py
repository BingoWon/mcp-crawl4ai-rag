#!/usr/bin/env python3
"""
æµ‹è¯•æ‰¹æ¬¡çº§åˆ«æ ‡è®°ä¿®å¤

éªŒè¯ä¿®å¤åçš„æ‰¹é‡æ›´æ–°å·¥å…·æ˜¯å¦æ­£ç¡®æ ‡è®°processed_atå­—æ®µ
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))
sys.path.insert(0, str(project_root / "tools"))

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv(project_root / ".env")

from src.database import create_database_client, DatabaseOperations
from src.utils.logger import setup_logger

logger = setup_logger(__name__)


async def test_batch_marking():
    """æµ‹è¯•æ‰¹æ¬¡çº§åˆ«æ ‡è®°åŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•æ‰¹æ¬¡çº§åˆ«æ ‡è®°ä¿®å¤...")
    
    # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
    db_client = create_database_client()
    await db_client.initialize()
    db_operations = DatabaseOperations(db_client)
    
    try:
        # æµ‹è¯•1ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„æ•°æ®
        logger.info("=" * 60)
        logger.info("æµ‹è¯•1ï¼šæ£€æŸ¥å¾…å¤„ç†æ•°æ®")
        
        batch = await db_operations.get_process_urls_batch(5)
        logger.info(f"ğŸ“Š è·å–åˆ° {len(batch)} ä¸ªå¾…å¤„ç†é¡µé¢")
        
        if not batch:
            logger.warning("âš ï¸ æ²¡æœ‰å¾…å¤„ç†çš„é¡µé¢ï¼Œæµ‹è¯•æ— æ³•è¿›è¡Œ")
            return
        
        # æ˜¾ç¤ºè·å–åˆ°çš„é¡µé¢
        for i, (url, content) in enumerate(batch):
            logger.info(f"   é¡µé¢{i+1}: {url[:80]}...")
            logger.info(f"   å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        
        # æµ‹è¯•2ï¼šæ¨¡æ‹Ÿæ‰¹æ¬¡å¤„ç†åçš„æ ‡è®°
        logger.info("=" * 60)
        logger.info("æµ‹è¯•2ï¼šæ¨¡æ‹Ÿæ‰¹æ¬¡æ ‡è®°")
        
        urls = [url for url, _ in batch]
        logger.info(f"ğŸ“ å‡†å¤‡æ ‡è®° {len(urls)} ä¸ªé¡µé¢ä¸ºå·²å¤„ç†...")
        
        # æ ‡è®°ä¸ºå·²å¤„ç†
        marked_count = await db_operations.mark_pages_processed(urls)
        logger.info(f"âœ… æˆåŠŸæ ‡è®°äº† {marked_count} ä¸ªé¡µé¢")
        
        # æµ‹è¯•3ï¼šéªŒè¯æ ‡è®°æ•ˆæœ
        logger.info("=" * 60)
        logger.info("æµ‹è¯•3ï¼šéªŒè¯æ ‡è®°æ•ˆæœ")
        
        # å†æ¬¡å°è¯•è·å–ç›¸åŒçš„æ‰¹æ¬¡
        new_batch = await db_operations.get_process_urls_batch(5)
        logger.info(f"ğŸ“Š å†æ¬¡è·å–åˆ° {len(new_batch)} ä¸ªå¾…å¤„ç†é¡µé¢")
        
        # æ£€æŸ¥æ˜¯å¦è·å–åˆ°äº†ä¸åŒçš„é¡µé¢
        if new_batch:
            new_urls = [url for url, _ in new_batch]
            overlap = set(urls) & set(new_urls)
            
            if overlap:
                logger.error(f"âŒ å‘ç°é‡å¤é¡µé¢: {len(overlap)} ä¸ª")
                for url in list(overlap)[:3]:
                    logger.error(f"   é‡å¤: {url[:80]}...")
            else:
                logger.info("âœ… æ²¡æœ‰é‡å¤é¡µé¢ï¼Œæ ‡è®°åŠŸèƒ½æ­£å¸¸")
        else:
            logger.info("âœ… æ²¡æœ‰æ›´å¤šå¾…å¤„ç†é¡µé¢ï¼Œå¯èƒ½æ‰€æœ‰é¡µé¢éƒ½å·²æ ‡è®°")
        
        # æµ‹è¯•4ï¼šç»Ÿè®¡ä¿¡æ¯
        logger.info("=" * 60)
        logger.info("æµ‹è¯•4ï¼šç»Ÿè®¡ä¿¡æ¯")
        
        # æŸ¥è¯¢æ€»æ•°å’Œå·²å¤„ç†æ•°
        total_result = await db_client.fetch_one("""
            SELECT COUNT(*) as count FROM pages
            WHERE content IS NOT NULL AND content != ''
            AND (url = 'https://developer.apple.com/documentation'
                 OR url LIKE 'https://developer.apple.com/documentation/%')
        """)
        
        processed_result = await db_client.fetch_one("""
            SELECT COUNT(*) as count FROM pages
            WHERE processed_at IS NOT NULL
            AND content IS NOT NULL AND content != ''
            AND (url = 'https://developer.apple.com/documentation'
                 OR url LIKE 'https://developer.apple.com/documentation/%')
        """)
        
        unprocessed_result = await db_client.fetch_one("""
            SELECT COUNT(*) as count FROM pages
            WHERE processed_at IS NULL
            AND content IS NOT NULL AND content != ''
            AND (url = 'https://developer.apple.com/documentation'
                 OR url LIKE 'https://developer.apple.com/documentation/%')
        """)
        
        total = total_result['count']
        processed = processed_result['count']
        unprocessed = unprocessed_result['count']
        
        logger.info(f"ğŸ“Š Appleæ–‡æ¡£ç»Ÿè®¡:")
        logger.info(f"   æ€»æ•°: {total}")
        logger.info(f"   å·²å¤„ç†: {processed}")
        logger.info(f"   æœªå¤„ç†: {unprocessed}")
        logger.info(f"   å¤„ç†è¿›åº¦: {(processed/total*100):.2f}%")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        
    finally:
        await db_client.close()
        logger.info("ğŸ”’ æ•°æ®åº“è¿æ¥å·²å…³é—­")


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•æ‰¹æ¬¡çº§åˆ«æ ‡è®°ä¿®å¤...")
    await test_batch_marking()
    logger.info("ğŸ‰ æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())
